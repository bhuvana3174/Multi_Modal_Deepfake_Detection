{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36110,"status":"ok","timestamp":1701844023456,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"},"user_tz":-330},"id":"m_Q-8vmYTW8b","outputId":"f8fc9145-04ec-4dc4-8c4b-4b5bc445d398"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ugxc3fgTTCxX"},"outputs":[],"source":["import pandas as pd\n","data= pd.read_csv(\"drive/MyDrive/Colab Notebooks/Final_Year_Project/FakeAVCeleb_v1.2/meta_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jbtk2qZjTud0"},"outputs":[],"source":["data.head()\n","del data[\"source\"]\n","del data[\"target1\"]\n","del data[\"target2\"]\n","del data[\"method\"]\n","del data[\"category\"]\n","del data[\"race\"]\n","del data[\"path\"]\n","del data[\"gender\"]\n","data.head()\n","\n","num_rows=len(data)\n","file_names = []\n","replace_dict = {\n","    \"RealVideo-RealAudio\": 3,\n","    \"RealVideo-FakeAudio\": 2,\n","    \"FakeVideo-RealAudio\": 1,\n","    \"FakeVideo-FakeAudio\": 0\n","}\n","for i in range(num_rows):\n","    temp = data[\"file_path\"][i]\n","    file_names.append(f\"{temp}/videoNo_{i}\")\n","    data['type'].replace(replace_dict, inplace=True)\n","\n","data[\"file_names\"] = file_names\n","del data[\"file_path\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1700027855224,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"},"user_tz":-330},"id":"OJC9rsphbdGO","outputId":"2aa61abf-178e-4ddb-a7d5-d7e242b90065"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","labels = [0, 1, 2, 3]\n","value_counts = data['type'].value_counts()\n","plt.bar (labels, value_counts)\n","\n","# Add the labels on the x-axis\n","plt.xticks (labels)\n","plt.title('Distribution of Data by Type')\n","plt.xlabel('Type')\n","plt.ylabel('Count')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1700027855224,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"},"user_tz":-330},"id":"xBgGj-aSm3K0","outputId":"adca3fc1-62f1-436b-8394-6c8311118f56"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   type                                         file_names  video_label  \\\n","0     3  FakeAVCeleb/RealVideo-RealAudio/African/men/id...            1   \n","1     3  FakeAVCeleb/RealVideo-RealAudio/African/men/id...            1   \n","2     3  FakeAVCeleb/RealVideo-RealAudio/African/men/id...            1   \n","3     3  FakeAVCeleb/RealVideo-RealAudio/African/men/id...            1   \n","4     3  FakeAVCeleb/RealVideo-RealAudio/African/men/id...            1   \n","\n","   audio_label  \n","0            1  \n","1            1  \n","2            1  \n","3            1  \n","4            1  "],"text/html":["\n","  <div id=\"df-52f97692-7c83-4a06-8301-98db72548825\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>type</th>\n","      <th>file_names</th>\n","      <th>video_label</th>\n","      <th>audio_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>FakeAVCeleb/RealVideo-RealAudio/African/men/id...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>FakeAVCeleb/RealVideo-RealAudio/African/men/id...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>FakeAVCeleb/RealVideo-RealAudio/African/men/id...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>FakeAVCeleb/RealVideo-RealAudio/African/men/id...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>FakeAVCeleb/RealVideo-RealAudio/African/men/id...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52f97692-7c83-4a06-8301-98db72548825')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-52f97692-7c83-4a06-8301-98db72548825 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-52f97692-7c83-4a06-8301-98db72548825');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ca8a14fd-07b2-4687-beaf-ce8481813726\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca8a14fd-07b2-4687-beaf-ce8481813726')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ca8a14fd-07b2-4687-beaf-ce8481813726 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":5}],"source":["import pandas as pd\n","video_label = []\n","audio_label = []\n","\n","for file_name in data['file_names']:\n","    if 'RealVideo' in file_name:\n","        video_label.append(1)\n","    elif 'FakeVideo' in file_name:\n","        video_label.append(0)\n","\n","    if 'RealAudio' in file_name:\n","        audio_label.append(1)\n","    elif 'FakeAudio' in file_name:\n","        audio_label.append(0)\n","data[\"video_label\"]=video_label\n","data[\"audio_label\"]=audio_label\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKArh84FaKty"},"outputs":[],"source":["data = data.sample(frac=1).reset_index(drop=True)\n","train_ratio=0.8\n","split_index = int(len(data)*train_ratio)\n","train_data = data.iloc[:split_index]\n","test_data = data.iloc[split_index:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dpQeqrJOZfjN"},"outputs":[],"source":["import os\n","import cv2\n","import torch\n","from torch.utils.data import Dataset\n","import numpy as np\n","batch_size = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZbwnS-EL9pSq"},"outputs":[],"source":["type_0_data = train_data[train_data['type'] == 0].head(500)\n","type_1_data = train_data[train_data['type'] == 1].head(500)\n","final_data = pd.concat([type_0_data, type_1_data, train_data[train_data['type'].isin([2, 3])]])\n","train_data = final_data\n","\n","type_0_data = test_data[test_data['type'] == 0].head(100)\n","type_1_data = test_data[test_data['type'] == 1].head(100)\n","final_data = pd.concat([type_0_data, type_1_data, test_data[test_data['type'].isin([2, 3])]])\n","test_data = final_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20879,"status":"ok","timestamp":1700027881977,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"},"user_tz":-330},"id":"Q0TF59nS-kNd","outputId":"ec2c7dfc-85b8-496c-f2cf-ed7e0eaec4a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.35.1-py3-none-any.whl (7.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.19.1-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.1/311.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":801,"status":"ok","timestamp":1700027882766,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"},"user_tz":-330},"id":"z5BgZM02hN5X","outputId":"d3d07f97-d4af-4cf0-dcf6-29cd86c61e58"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","labels = [0, 1, 2, 3]\n","value_counts = test_data['type'].value_counts()\n","plt.bar (labels, value_counts)\n","\n","# Add the labels on the x-axis\n","plt.xticks (labels)\n","plt.title('Distribution of Data by Type')\n","plt.xlabel('Type')\n","plt.ylabel('Count')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":724,"status":"ok","timestamp":1700027883477,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"},"user_tz":-330},"id":"3w0XdwmehiWB","outputId":"5eb22c6b-18bd-41fd-863c-ce1e85c6e599"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      type                                         file_names  video_label  \\\n","0        3  FakeAVCeleb/RealVideo-RealAudio/African/men/id...            1   \n","1        1  FakeAVCeleb/FakeVideo-RealAudio/African/women/...            0   \n","2        1  FakeAVCeleb/FakeVideo-RealAudio/Caucasian (Eur...            0   \n","3        0  FakeAVCeleb/FakeVideo-FakeAudio/Caucasian (Ame...            0   \n","4        2  FakeAVCeleb/RealVideo-FakeAudio/Caucasian (Ame...            1   \n","...    ...                                                ...          ...   \n","1782     2  FakeAVCeleb/RealVideo-FakeAudio/African/women/...            1   \n","1783     0  FakeAVCeleb/FakeVideo-FakeAudio/Asian (South)/...            0   \n","1784     1  FakeAVCeleb/FakeVideo-RealAudio/Asian (South)/...            0   \n","1785     0  FakeAVCeleb/FakeVideo-FakeAudio/Caucasian (Ame...            0   \n","1786     2  FakeAVCeleb/RealVideo-FakeAudio/Asian (South)/...            1   \n","\n","      audio_label  \n","0               1  \n","1               1  \n","2               1  \n","3               0  \n","4               0  \n","...           ...  \n","1782            0  \n","1783            0  \n","1784            1  \n","1785            0  \n","1786            0  \n","\n","[1787 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-4c9fa4d9-eb38-4e73-b792-e2d5e276868b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>type</th>\n","      <th>file_names</th>\n","      <th>video_label</th>\n","      <th>audio_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>FakeAVCeleb/RealVideo-RealAudio/African/men/id...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>FakeAVCeleb/FakeVideo-RealAudio/African/women/...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>FakeAVCeleb/FakeVideo-RealAudio/Caucasian (Eur...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>FakeAVCeleb/FakeVideo-FakeAudio/Caucasian (Ame...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>FakeAVCeleb/RealVideo-FakeAudio/Caucasian (Ame...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1782</th>\n","      <td>2</td>\n","      <td>FakeAVCeleb/RealVideo-FakeAudio/African/women/...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1783</th>\n","      <td>0</td>\n","      <td>FakeAVCeleb/FakeVideo-FakeAudio/Asian (South)/...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1784</th>\n","      <td>1</td>\n","      <td>FakeAVCeleb/FakeVideo-RealAudio/Asian (South)/...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1785</th>\n","      <td>0</td>\n","      <td>FakeAVCeleb/FakeVideo-FakeAudio/Caucasian (Ame...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1786</th>\n","      <td>2</td>\n","      <td>FakeAVCeleb/RealVideo-FakeAudio/Asian (South)/...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1787 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c9fa4d9-eb38-4e73-b792-e2d5e276868b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4c9fa4d9-eb38-4e73-b792-e2d5e276868b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4c9fa4d9-eb38-4e73-b792-e2d5e276868b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bd7ba4fe-1097-435c-a97e-b1273273eb1f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd7ba4fe-1097-435c-a97e-b1273273eb1f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bd7ba4fe-1097-435c-a97e-b1273273eb1f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":11}],"source":["import pandas as pd\n","from sklearn.utils import shuffle\n","\n","# Assuming train_data is your DataFrame\n","shuffled_data = shuffle(train_data)\n","\n","# Reset the index of the shuffled DataFrame\n","shuffled_data.reset_index(drop=True, inplace=True)\n","train_data = shuffled_data\n","train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["3f0988bb144d402c9a8d61dd001b7b35","9a1d7b3de1dc4686b4b6045a1c2a2487","c835c837b6c748f8bdf8c6f343749d5d","9e5cf2c8791e4fabaee5a268d02f5d0b","c6cdea92c21f4d228f5300ff17e45692","84adb3440c044db0977a0f6c6e1ca58e","a8499717904f4a78811b28d5a7cc21f7","ad548e9bfe4c4666a0f4017a2709a0d6","3fd2a35c54d24afcaa773ac39db0933e","05f43b3b6d7b47a7b2eece922a3a28be","8cd202cc36ea47e4971b52915a63765c"]},"executionInfo":{"elapsed":5646,"status":"ok","timestamp":1700027889111,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"},"user_tz":-330},"id":"S3QYmOcRZkzZ","outputId":"af46eea5-8fa8-4400-a50a-be2e5ca20c78"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)rocessor_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f0988bb144d402c9a8d61dd001b7b35"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"]}],"source":["from transformers import AutoImageProcessor, SwinModel\n","import time\n","\n","base_frame_path = \"drive/MyDrive/Colab Notebooks/Final_Year_Project/output_faces/\"\n","base_mel_path = \"drive/MyDrive/Colab Notebooks/Final_Year_Project/output_audios_melspectogram/\"\n","image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, data_paths):\n","        self.data_paths = data_paths\n","\n","    def __len__(self):\n","        return len(self.data_paths)\n","\n","    def __getitem__(self, idx):\n","        folder_path = self.data_paths[\"file_names\"][idx]\n","        frames,mel = self.load_frames(folder_path)\n","        labels = [0,0,0,0]\n","        labels[self.data_paths[\"type\"][idx]] = 1\n","        # print(frames)\n","        # return torch.tensor(frames), torch.tensor(mel), [self.data_paths[\"type\"][idx],self.data_paths[\"video_label\"][idx],self.data_paths[\"audio_label\"][idx]]\n","        return frames, mel, torch.tensor(np.array(labels, dtype=np.float32))\n","\n","    def load_frames(self, folder_path):\n","        frames = []\n","        # start = time.time()\n","\n","        for frame_file in os.listdir(base_frame_path+folder_path):\n","            if frame_file.endswith('.jpg') or frame_file.endswith('.png'):\n","                frame_path = os.path.join(base_frame_path+folder_path, frame_file)\n","                frame = cv2.imread(frame_path)\n","                frame = image_processor(frame, return_tensors=\"pt\")\n","                frames.append(frame)\n","\n","        mel_path = base_mel_path + folder_path + \".png\"\n","        mel = cv2.imread(mel_path)\n","        mel = image_processor(mel, return_tensors=\"pt\")\n","\n","        # end = time.time()\n","        # print(\"Time for preprocessing : \", start-end)\n","\n","        return frames, mel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ft7qZNapdSQ4"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5593,"status":"ok","timestamp":1700027894694,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"},"user_tz":-330},"id":"kkl-g9OIdpzD","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["332168099f6c413095e2bb0f2377ec1a","8b1db89d43d74dd4960a307b58e9f71c","1aad9672b8b944fd835cf1500072c4a1","53a3345c21f74caabf22fa26b099dc99","90a8b4ce0ed742eb9af562dc02f8c90e","914b77d808594894ba871a59ffc7c02b","db9ba6357f1646f0b80c861c1328ec7f","6f921194c14e4d71b487f047a14a67a8","1ec00445225243edb2026c6dad961fe1","8a1ac803ef0a4210a04d8f18c8e62ff3","a9a0d58c0134430fbceea4e2a7aeefe6","24dc9cd45d5644a09c02a8fd4eae36f3","2ed6ab70687e470798206c1ac7daafc1","68eeff0e1a6a4ff7bf2f4bd98107a393","4fc194aa3a074565b30c6de113b62d9a","f9c7e24f0047449a9f8d25856058988f","c5a28e8b0c874f0cb7741ae55fc2bc22","66e278b7e9c4412da2e7c7ffcf2c3b1e","27b9c2da62a24128bb8c0d008759f6f1","bf0cbbd1a66d4d77b9f6e38a001b58cc","2a52234d35bf46c2a1d20aafd4d23fe3","517caecf9dd2476688a4629c81a14796"]},"outputId":"fbef979b-46af-42ed-e2d3-5f803c5faab3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/71.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"332168099f6c413095e2bb0f2377ec1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/113M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24dc9cd45d5644a09c02a8fd4eae36f3"}},"metadata":{}}],"source":["import torch\n","import torch.nn as nn\n","from torchvision.models import swin_transformer\n","\n","vis_model =  SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n","aud_model =  SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n","\n","# print(swin_transformer.swin_b())\n","\n","# vis_model = nn.Sequential(*list(vis_model.children())[:-1])\n","# aud_model = nn.Sequential(*list(aud_model.children())[:-1])\n","# nn.Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","# vis_model[0][0][0] = nn.Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","# print(vis_model)\n","# Move the model to the appropriate device (CPU or GPU)\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# vis_model.to(device)\n","# aud_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftXlGPcvYePh"},"outputs":[],"source":["# freezing the pretrained models\n","\n","for param in aud_model.parameters():\n","    param.requires_grad = False\n","\n","for param in vis_model.parameters():\n","    param.requires_grad = False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crTuuVq6P4AR"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class AudioAndVideoConcat(nn.Module):\n","    def __init__(self, video_module, audio_module, num_classes):\n","\n","        super(AudioAndVideoConcat, self).__init__()\n","\n","        self.video_module = video_module\n","        self.audio_module = audio_module\n","        self.fusion = torch.nn.Linear(in_features=4096*2,out_features=4096)\n","        self.reduce_lay = torch.nn.Linear(in_features=49*768,out_features=4096)\n","        self.fc = torch.nn.Linear(in_features=4096,out_features=num_classes)\n","        self.dropout = torch.nn.Dropout(0.8)\n","        self.fc = nn.Linear(4096, num_classes)  # Concatenating features\n","\n","        # self.convolutional_layer = torch.nn.Conv1d(in_channels=49, out_channels=32, kernel_size=3, padding=1)\n","\n","    def forward(self, video_frames, mel_spectogram):\n","        # video_features.last_hidden_state = torch.zeros(1, 49, 768)\n","\n","\n","        # for i in range(1 if len(video_frames)-1 == 0 else len(video_frames)-1):\n","        for i in range(len(video_frames)):\n","          with torch.no_grad():\n","            swin_vid_features = self.video_module(**video_frames[i]).last_hidden_state\n","          video_features = torch.nn.functional.relu(self.reduce_lay(swin_vid_features.view(1,-1)))\n","\n","        with torch.no_grad():\n","          swin_aud_features = self.audio_module(**mel_spectogram).last_hidden_state\n","        audio_features = torch.nn.functional.relu(self.reduce_lay(swin_aud_features.view(1,-1)))\n","\n","        # print(video_features.shape,audio_features.shape)\n","        # flattened_video_features = torch.nn.functional.max_pool1d(self.convolutional_layer(video_features.last_hidden_state), kernel_size=32, stride=32)\n","        # flattened_audio_features = torch.nn.functional.max_pool1d(self.convolutional_layer(audio_features.last_hidden_state), kernel_size=32, stride=32)\n","        # # print(\"pjhbhbh\",flattened_video_features.shape)\n","        # flattened_video_features = flattened_video_features.view(1, 768)\n","        # flattened_audio_features = flattened_audio_features.view(1, 768)\n","        # print(flattened_video_features.shape, flattened_audio_features.shape)\n","        # flattened_video_features = video_features.view(1, 37632)\n","        # flattened_audio_features = audio_features.view(1, 37632)\n","        # print(video_features.shape, audio_features.shape)\n","\n","        concatenated_features = torch.cat((video_features, audio_features), dim=1)  # Concatenating features\n","        fused = self.dropout(torch.nn.functional.relu(self.fusion(concatenated_features)))\n","        output = self.fc(fused)\n","        softmax_output = F.softmax(output)\n","\n","\n","        return softmax_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5OqEmZehCaU"},"outputs":[],"source":["num_classes = 4  # Specify the number of classes in your task\n","multimodal_model = AudioAndVideoConcat(vis_model, aud_model, num_classes)\n","optimizer = torch.optim.Adam(multimodal_model.parameters(), lr=0.000005,betas=(0.9, 0.999))\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6kC597x4dLKR"},"outputs":[],"source":["#reduction\n","train_dataset = CustomDataset(train_data)\n","test_dataset = CustomDataset(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":530},"executionInfo":{"elapsed":15815,"status":"error","timestamp":1699989052683,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"},"user_tz":-330},"id":"UDsMAQet9Nm7","outputId":"69e9dbe0-5dd6-41e6-dabd-1dd849f591ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["1810 390\n","Time for preprocessing :  6.771913528442383\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"name":"stdout","output_type":"stream","text":["Time for training :  3.9692165851593018\n","tensor([[0.2923, 0.2828, 0.2680, 0.1568]], grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  748  Loss =  tensor(1.3549, grad_fn=<DivBackward1>)\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-be9ab37e14ac>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m               \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m               \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 state_steps)\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    312\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_epochs = 10\n","print(len(train_data),len(test_data))\n","\n","for epoch in range(num_epochs):\n","    for bth_idx in range(748,len(train_data)):\n","          # Forward pass\n","          start = time.time()\n","          frames,mel,labels = train_dataset.__getitem__(bth_idx)\n","          end = time.time()\n","\n","          print(\"Time for preprocessing : \", end-start)\n","\n","\n","          if len(frames) != 0 :\n","\n","              start = time.time()\n","              outputs = multimodal_model(frames, mel)\n","              end = time.time()\n","\n","              print(\"Time for training : \", end-start)\n","\n","              labels = torch.unsqueeze(labels, dim=0)\n","              print(outputs,labels)\n","              loss = criterion(outputs, labels)\n","              print(\"Index = \",bth_idx,\" Loss = \",loss)\n","              # Backward pass and optimization\n","\n","              start = time.time()\n","              optimizer.zero_grad()\n","              loss.backward()\n","              optimizer.step()\n","              end = time.time()\n","\n","              print(\"Time for optimisation : \",  end-start)\n","\n","              # check point\n","              if bth_idx%100 == 0 :\n","                  checkpoint = {\n","                      'epoch': epoch,\n","                      'model_state_dict': multimodal_model.state_dict(),\n","                      'optimizer_state_dict': optimizer.state_dict(),\n","                      'loss': loss,\n","                      'bth_idx':bth_idx,\n","                      'train_data' : train_data,\n","                      'test_data':test_data\n","                  }\n","                  torch.save(checkpoint, 'drive/MyDrive/Colab Notebooks/Final_Year_Project/model_reduced_dataset_checkpoint.pth')\n","\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":39965,"status":"ok","timestamp":1701844063417,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"},"user_tz":-330},"id":"7KSYh6jDi2lv"},"outputs":[],"source":["import torch\n","checkpoint = torch.load('drive/MyDrive/Colab Notebooks/Final_Year_Project/model_reduced_dataset_checkpoint.pth')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":678},"executionInfo":{"elapsed":1482,"status":"ok","timestamp":1701844154597,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"},"user_tz":-330},"id":"kfELwY1v_lEg","outputId":"02a6349c-2020-46bc-b55f-5b65b2606d3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["1788 412 7 400\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["   level_0  index  type                                         file_names  \\\n","0        0  17253     0  FakeAVCeleb/FakeVideo-FakeAudio/Asian (South)/...   \n","1        1  17256     0  FakeAVCeleb/FakeVideo-FakeAudio/Asian (East)/w...   \n","2        2  17257     0  FakeAVCeleb/FakeVideo-FakeAudio/Caucasian (Ame...   \n","3        3  17258     0  FakeAVCeleb/FakeVideo-FakeAudio/Caucasian (Eur...   \n","4        4  17260     0  FakeAVCeleb/FakeVideo-FakeAudio/Caucasian (Ame...   \n","\n","   video_label  audio_label  \n","0            0            0  \n","1            0            0  \n","2            0            0  \n","3            0            0  \n","4            0            0  "],"text/html":["\n","  <div id=\"df-add608e5-161d-45d0-9869-dad67645b033\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>level_0</th>\n","      <th>index</th>\n","      <th>type</th>\n","      <th>file_names</th>\n","      <th>video_label</th>\n","      <th>audio_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>17253</td>\n","      <td>0</td>\n","      <td>FakeAVCeleb/FakeVideo-FakeAudio/Asian (South)/...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>17256</td>\n","      <td>0</td>\n","      <td>FakeAVCeleb/FakeVideo-FakeAudio/Asian (East)/w...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>17257</td>\n","      <td>0</td>\n","      <td>FakeAVCeleb/FakeVideo-FakeAudio/Caucasian (Ame...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>17258</td>\n","      <td>0</td>\n","      <td>FakeAVCeleb/FakeVideo-FakeAudio/Caucasian (Eur...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>17260</td>\n","      <td>0</td>\n","      <td>FakeAVCeleb/FakeVideo-FakeAudio/Caucasian (Ame...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-add608e5-161d-45d0-9869-dad67645b033')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-add608e5-161d-45d0-9869-dad67645b033 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-add608e5-161d-45d0-9869-dad67645b033');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8bc6b047-a405-4609-9c0d-42d2dc1f6a5b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8bc6b047-a405-4609-9c0d-42d2dc1f6a5b')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8bc6b047-a405-4609-9c0d-42d2dc1f6a5b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":6}],"source":["num_epochs = 10\n","last_epoch = checkpoint['epoch']\n","last_index = checkpoint['bth_idx']\n","multimodal_model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","loss = checkpoint['loss']\n","train_data = checkpoint['train_data']\n","test_data = checkpoint['test_data']\n","print(len(train_data),len(test_data),last_epoch, last_index)\n","# test_data = test_data.reset_index()\n","\n","\n","train_dataset = CustomDataset(train_data)\n","test_dataset = CustomDataset(test_data)\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","labels = [0, 1, 2, 3]\n","value_counts = test_data['type'].value_counts()\n","plt.bar (labels, value_counts)\n","\n","# Add the labels on the x-axis\n","plt.xticks (labels)\n","plt.title('Distribution of Data by Type')\n","plt.xlabel('Type')\n","plt.ylabel('Count')\n","plt.show()\n","\n","test_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6eNyoySuoAe8","executionInfo":{"status":"error","timestamp":1700045746641,"user_tz":-330,"elapsed":2727466,"user":{"displayName":"Paras Patle","userId":"17529481869009019309"}},"outputId":"425a96bb-057e-4267-903f-3f6f9acee4dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch no.  7\n","Time for preprocessing :  0.11707830429077148\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["Time for training :  2.686042547225952\n","tensor([[1.7161e-08, 9.9974e-01, 3.3089e-11, 2.5724e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  101  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.339745283126831\n","Time for preprocessing :  0.15489721298217773\n","Time for training :  2.9744350910186768\n","tensor([[1.8750e-05, 9.9998e-01, 1.0587e-11, 2.6224e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  102  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.279607772827148\n","Time for preprocessing :  0.07116484642028809\n","Time for training :  1.7482929229736328\n","tensor([[2.0678e-03, 2.6465e-10, 9.9793e-01, 4.2426e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  103  Loss =  tensor(0.7451, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.27945876121521\n","Time for preprocessing :  0.0800333023071289\n","Time for training :  1.871983289718628\n","tensor([[6.9975e-08, 8.6767e-03, 9.9815e-06, 9.9131e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  104  Loss =  tensor(0.7498, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.595839262008667\n","Time for preprocessing :  0.19026803970336914\n","Time for training :  4.860356092453003\n","tensor([[3.4407e-07, 4.8357e-03, 2.0103e-04, 9.9496e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  105  Loss =  tensor(0.7472, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.414875030517578\n","Time for preprocessing :  0.11334800720214844\n","Time for training :  2.6721231937408447\n","tensor([[9.6182e-09, 1.0000e+00, 2.4757e-13, 4.1974e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  106  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  3.857417583465576\n","Time for preprocessing :  0.09325361251831055\n","Time for training :  2.140639066696167\n","tensor([[5.8382e-10, 1.4311e-06, 1.3379e-05, 9.9999e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  107  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.7026379108428955\n","Time for preprocessing :  0.13874268531799316\n","Time for training :  2.834508180618286\n","tensor([[2.8218e-02, 9.7171e-01, 1.9048e-06, 7.2750e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  108  Loss =  tensor(1.7072, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.183913469314575\n","Time for preprocessing :  0.08797574043273926\n","Time for training :  1.940406322479248\n","tensor([[1.7446e-05, 4.2881e-10, 9.9998e-01, 4.7276e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  109  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.007362127304077\n","Time for preprocessing :  0.11120986938476562\n","Time for training :  3.0103535652160645\n","tensor([[1.1258e-04, 9.9989e-01, 1.4473e-08, 1.0790e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  110  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.358087539672852\n","Time for preprocessing :  0.10030102729797363\n","Time for training :  1.7680635452270508\n","tensor([[9.9991e-01, 8.5655e-07, 8.8970e-05, 4.7280e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  111  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.266564846038818\n","Time for preprocessing :  0.07310771942138672\n","Time for training :  1.9078600406646729\n","tensor([[9.9995e-01, 5.1498e-05, 2.1498e-06, 2.4176e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  112  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.654446363449097\n","Time for preprocessing :  0.11656785011291504\n","Time for training :  3.163177013397217\n","tensor([[2.1366e-02, 6.7417e-06, 9.7863e-01, 3.7284e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  113  Loss =  tensor(0.7587, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.835204839706421\n","Time for preprocessing :  0.10148239135742188\n","Time for training :  2.700556755065918\n","tensor([[3.9882e-05, 1.8033e-02, 5.1481e-05, 9.8188e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  114  Loss =  tensor(0.7564, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.245342969894409\n","Time for preprocessing :  0.10276484489440918\n","Time for training :  3.041276454925537\n","tensor([[5.4279e-17, 3.2754e-07, 5.5411e-10, 1.0000e+00]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  115  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.304802179336548\n","Time for preprocessing :  0.1052100658416748\n","Time for training :  2.5697836875915527\n","tensor([[7.3522e-11, 1.0012e-03, 6.6823e-07, 9.9900e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  116  Loss =  tensor(0.7444, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.169412851333618\n","Time for preprocessing :  0.0737922191619873\n","Time for training :  1.9192302227020264\n","tensor([[9.9981e-01, 1.8515e-04, 1.4471e-06, 2.2202e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  117  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.008244752883911\n","Time for preprocessing :  0.11658382415771484\n","Time for training :  3.031527280807495\n","tensor([[1.0000e+00, 4.6169e-09, 1.0379e-08, 1.0091e-14]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  118  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.895958423614502\n","Time for preprocessing :  0.13839077949523926\n","Time for training :  2.306124210357666\n","tensor([[9.9999e-01, 7.2212e-06, 2.1955e-06, 7.7162e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  119  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.103790521621704\n","Time for preprocessing :  0.08223557472229004\n","Time for training :  1.7824630737304688\n","tensor([[2.0356e-03, 1.5999e-07, 9.9794e-01, 2.8638e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  120  Loss =  tensor(0.7451, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.7525413036346436\n","Time for preprocessing :  0.15361332893371582\n","Time for training :  3.670058488845825\n","tensor([[3.8647e-02, 3.6441e-06, 9.6135e-01, 9.6318e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  121  Loss =  tensor(0.7711, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.055112838745117\n","Time for preprocessing :  0.03993082046508789\n","Time for training :  0.8016107082366943\n","tensor([[9.9982e-01, 1.7423e-04, 4.2760e-06, 1.2552e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  122  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.239755392074585\n","Time for preprocessing :  0.10294675827026367\n","Time for training :  2.4312145709991455\n","tensor([[4.1912e-02, 1.8735e-09, 9.5809e-01, 6.0481e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  123  Loss =  tensor(0.7735, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.72304105758667\n","Time for preprocessing :  0.1663496494293213\n","Time for training :  4.5769267082214355\n","tensor([[1.6033e-02, 5.4740e-10, 9.8397e-01, 7.2507e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  124  Loss =  tensor(0.7550, grad_fn=<DivBackward1>)\n","Time for optimisation :  3.981383800506592\n","Time for preprocessing :  0.07093310356140137\n","Time for training :  1.843790054321289\n","tensor([[2.0448e-04, 9.9980e-01, 5.8702e-10, 2.2150e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  125  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.204677581787109\n","Time for preprocessing :  0.09818363189697266\n","Time for training :  2.650731325149536\n","tensor([[1.0000e+00, 3.9244e-07, 6.2981e-08, 1.5357e-12]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  126  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.273696184158325\n","Time for preprocessing :  0.13234663009643555\n","Time for training :  2.5701048374176025\n","tensor([[1.1560e-06, 1.0000e+00, 1.2965e-11, 4.1600e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  127  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.2173051834106445\n","Time for preprocessing :  0.09327936172485352\n","Time for training :  1.952413558959961\n","tensor([[9.9828e-01, 1.7087e-03, 1.2730e-05, 2.4144e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  128  Loss =  tensor(0.7449, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.232299089431763\n","Time for preprocessing :  0.1265857219696045\n","Time for training :  2.6609134674072266\n","tensor([[3.0383e-06, 1.0000e+00, 6.7027e-15, 7.3426e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  129  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.296384572982788\n","Time for preprocessing :  0.07448267936706543\n","Time for training :  1.914132833480835\n","tensor([[5.9315e-04, 1.8873e-08, 9.9941e-01, 1.5889e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  130  Loss =  tensor(0.7441, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.282250881195068\n","Time for preprocessing :  0.07942414283752441\n","Time for training :  1.9002258777618408\n","tensor([[1.8979e-05, 9.9996e-01, 1.5373e-09, 1.6057e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  131  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.785794258117676\n","Time for preprocessing :  0.10179281234741211\n","Time for training :  2.6037650108337402\n","tensor([[2.3750e-05, 9.9998e-01, 5.3577e-14, 3.6561e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  132  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.025415897369385\n","Time for preprocessing :  0.07360148429870605\n","Time for training :  1.7265644073486328\n","tensor([[1.7792e-04, 1.3080e-09, 9.9982e-01, 4.8375e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  133  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.0781872272491455\n","Time for preprocessing :  0.11648893356323242\n","Time for training :  3.0569651126861572\n","tensor([[4.4899e-02, 3.9766e-07, 9.5510e-01, 1.7519e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  134  Loss =  tensor(0.7756, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.183389186859131\n","Time for preprocessing :  0.09489822387695312\n","Time for training :  2.573209524154663\n","tensor([[1.0000e+00, 6.5994e-07, 8.5204e-10, 5.6318e-14]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  135  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.573480606079102\n","Time for preprocessing :  0.09732627868652344\n","Time for training :  2.158581256866455\n","tensor([[1.0163e-04, 9.9990e-01, 1.6258e-08, 6.2912e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  136  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.200806617736816\n","Time for preprocessing :  0.2716403007507324\n","Time for training :  7.19134521484375\n","tensor([[5.0429e-08, 1.0501e-02, 6.5047e-05, 9.8943e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  137  Loss =  tensor(0.7511, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.516196250915527\n","Time for preprocessing :  0.09717726707458496\n","Time for training :  2.5067250728607178\n","tensor([[3.4879e-04, 9.9962e-01, 6.6970e-08, 2.6173e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  138  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.305288553237915\n","Time for preprocessing :  0.14798521995544434\n","Time for training :  4.789791584014893\n","tensor([[1.3352e-05, 9.9999e-01, 2.3773e-12, 4.1514e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  139  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.905120372772217\n","Time for preprocessing :  0.10981249809265137\n","Time for training :  2.9441025257110596\n","tensor([[1.0000e+00, 2.1981e-08, 1.2778e-06, 3.8776e-12]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  140  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.665578126907349\n","Time for preprocessing :  0.16417384147644043\n","Time for training :  4.819706678390503\n","tensor([[2.5165e-02, 9.7482e-01, 2.4602e-07, 1.9360e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  141  Loss =  tensor(0.7615, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.186982870101929\n","Time for preprocessing :  0.10825777053833008\n","Time for training :  2.155245304107666\n","tensor([[9.9999e-01, 2.8966e-06, 2.2107e-06, 6.0661e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  142  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  3.8393664360046387\n","Time for preprocessing :  0.07464241981506348\n","Time for training :  1.8420097827911377\n","tensor([[2.0846e-07, 9.9998e-01, 3.3526e-11, 1.8272e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  143  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.579316139221191\n","Time for preprocessing :  0.09758949279785156\n","Time for training :  2.3983964920043945\n","tensor([[2.2216e-03, 2.2872e-10, 9.9778e-01, 3.2086e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  144  Loss =  tensor(0.7452, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.123681545257568\n","Time for preprocessing :  0.058261871337890625\n","Time for training :  1.0875885486602783\n","tensor([[1.0000e+00, 1.5270e-10, 3.3341e-09, 1.7846e-17]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  145  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.0334014892578125\n","Time for preprocessing :  0.1641075611114502\n","Time for training :  5.455996513366699\n","tensor([[2.1941e-08, 5.6096e-01, 2.6661e-07, 4.3904e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  146  Loss =  tensor(1.2293, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.247652292251587\n","Time for preprocessing :  0.1568129062652588\n","Time for training :  2.874501943588257\n","tensor([[2.5236e-06, 1.0000e+00, 2.6306e-12, 2.1724e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  147  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.751071929931641\n","Time for preprocessing :  0.16216516494750977\n","Time for training :  2.8558852672576904\n","tensor([[2.4168e-08, 3.4645e-03, 1.6562e-04, 9.9637e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  148  Loss =  tensor(0.7462, grad_fn=<DivBackward1>)\n","Time for optimisation :  3.818233013153076\n","Time for preprocessing :  0.0638284683227539\n","Time for training :  1.5544569492340088\n","tensor([[1.1390e-08, 1.0000e+00, 2.1278e-13, 1.9614e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  149  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.456228733062744\n","Time for preprocessing :  0.12207841873168945\n","Time for training :  2.3932290077209473\n","tensor([[9.9929e-01, 2.3498e-05, 6.8757e-04, 3.5722e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  150  Loss =  tensor(0.7442, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.70854926109314\n","Time for preprocessing :  0.07260251045227051\n","Time for training :  1.8609023094177246\n","tensor([[6.3312e-12, 2.9223e-04, 1.7390e-08, 9.9971e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  151  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.211852550506592\n","Time for preprocessing :  0.06880855560302734\n","Time for training :  1.6893973350524902\n","tensor([[4.5059e-06, 1.0529e-10, 1.0000e+00, 6.7396e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  152  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.671395540237427\n","Time for preprocessing :  0.15461182594299316\n","Time for training :  3.2539913654327393\n","tensor([[4.2052e-06, 9.9842e-01, 1.7063e-07, 1.5748e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  153  Loss =  tensor(0.7448, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.420869588851929\n","Time for preprocessing :  0.19560933113098145\n","Time for training :  3.8231558799743652\n","tensor([[9.9791e-01, 4.6751e-04, 1.6168e-03, 5.9880e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  154  Loss =  tensor(0.7451, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.752547979354858\n","Time for preprocessing :  0.11502218246459961\n","Time for training :  2.9286673069000244\n","tensor([[1.4362e-07, 1.3731e-04, 9.0612e-05, 9.9977e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  155  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.5248048305511475\n","Time for preprocessing :  0.11588525772094727\n","Time for training :  2.9980456829071045\n","tensor([[2.0815e-09, 1.7522e-12, 1.0000e+00, 1.1791e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  156  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.371595859527588\n","Time for preprocessing :  0.055426597595214844\n","Time for training :  1.0077605247497559\n","tensor([[2.9030e-06, 2.6535e-10, 1.0000e+00, 1.8576e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  157  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.429620742797852\n","Time for preprocessing :  0.15056943893432617\n","Time for training :  3.743006944656372\n","tensor([[1.6642e-10, 3.3377e-05, 3.1419e-05, 9.9994e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  158  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.846108436584473\n","Time for preprocessing :  0.1284332275390625\n","Time for training :  3.525611162185669\n","tensor([[1.1310e-05, 6.3545e-10, 9.9997e-01, 1.7129e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  159  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.326573848724365\n","Time for preprocessing :  0.09482693672180176\n","Time for training :  2.4730794429779053\n","tensor([[9.3831e-03, 9.5031e-01, 3.5305e-04, 3.9956e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  160  Loss =  tensor(0.7791, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.157639026641846\n","Time for preprocessing :  0.08567094802856445\n","Time for training :  2.992633581161499\n","tensor([[9.8168e-01, 2.8444e-07, 1.8325e-02, 3.0281e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  161  Loss =  tensor(0.7566, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.306429147720337\n","Time for preprocessing :  0.11018729209899902\n","Time for training :  2.2397873401641846\n","tensor([[4.1141e-03, 9.9583e-01, 1.6111e-09, 5.1906e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  162  Loss =  tensor(0.7466, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.313675880432129\n","Time for preprocessing :  0.09900617599487305\n","Time for training :  2.120069742202759\n","tensor([[9.4206e-08, 6.4939e-05, 6.3445e-06, 9.9993e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  163  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.629269599914551\n","Time for preprocessing :  0.10158348083496094\n","Time for training :  2.62520170211792\n","tensor([[1.1563e-05, 9.9999e-01, 3.9473e-10, 1.4400e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  164  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.264200687408447\n","Time for preprocessing :  0.06131482124328613\n","Time for training :  1.548231601715088\n","tensor([[1.4294e-03, 9.9783e-01, 8.6103e-07, 7.3817e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  165  Loss =  tensor(0.7452, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.211597681045532\n","Time for preprocessing :  0.08839583396911621\n","Time for training :  1.993765115737915\n","tensor([[9.9776e-01, 8.1645e-04, 1.3736e-03, 5.0249e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  166  Loss =  tensor(0.7452, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.878049612045288\n","Time for preprocessing :  0.11475729942321777\n","Time for training :  2.4458560943603516\n","tensor([[4.5385e-08, 9.9980e-01, 2.5650e-09, 1.9966e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  167  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.733033657073975\n","Time for preprocessing :  0.07931947708129883\n","Time for training :  2.1408815383911133\n","tensor([[9.9999e-01, 2.0492e-06, 8.7880e-06, 1.1143e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  168  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  3.994206666946411\n","Time for preprocessing :  0.10064363479614258\n","Time for training :  2.8070430755615234\n","tensor([[3.5843e-04, 6.6708e-06, 9.9809e-01, 1.5494e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  169  Loss =  tensor(0.7450, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.404825448989868\n","Time for preprocessing :  0.10400938987731934\n","Time for training :  2.507445812225342\n","tensor([[9.9998e-01, 1.2699e-05, 5.0707e-06, 2.5767e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  170  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.441075801849365\n","Time for preprocessing :  0.06352972984313965\n","Time for training :  1.534106969833374\n","tensor([[2.1850e-01, 3.9152e-09, 7.8088e-01, 6.2361e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  171  Loss =  tensor(1.4731, grad_fn=<DivBackward1>)\n","Time for optimisation :  3.914271354675293\n","Time for preprocessing :  0.1381998062133789\n","Time for training :  7.464874744415283\n","tensor([[3.0971e-05, 9.9997e-01, 4.6385e-11, 7.7591e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  172  Loss =  tensor(1.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  10.72121286392212\n","Time for preprocessing :  0.08264517784118652\n","Time for training :  1.8204567432403564\n","tensor([[6.8236e-06, 9.9801e-01, 1.9338e-08, 1.9872e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  173  Loss =  tensor(0.7451, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.66785454750061\n","Time for preprocessing :  0.09162497520446777\n","Time for training :  2.445448160171509\n","tensor([[2.5916e-05, 9.9991e-01, 1.3514e-09, 5.9641e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  174  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.49686074256897\n","Time for preprocessing :  0.1820507049560547\n","Time for training :  4.44541072845459\n","tensor([[4.7337e-03, 7.4466e-05, 9.7331e-01, 2.1878e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  175  Loss =  tensor(0.7625, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.628836154937744\n","Time for preprocessing :  0.06889867782592773\n","Time for training :  1.8364686965942383\n","tensor([[8.1467e-08, 1.9540e-15, 1.0000e+00, 7.6462e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  176  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.765104055404663\n","Time for preprocessing :  0.05772757530212402\n","Time for training :  1.4981467723846436\n","tensor([[1.0000e+00, 6.3628e-08, 2.9829e-07, 1.5522e-12]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  177  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.2059006690979\n","Time for preprocessing :  0.09770774841308594\n","Time for training :  2.2649166584014893\n","tensor([[1.2078e-06, 1.0000e+00, 2.5848e-09, 1.7912e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  178  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.275834321975708\n","Time for preprocessing :  0.1232759952545166\n","Time for training :  3.139408588409424\n","tensor([[4.9003e-08, 9.5163e-01, 3.9066e-08, 4.8374e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  179  Loss =  tensor(0.7782, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.517881393432617\n","Time for preprocessing :  0.10172414779663086\n","Time for training :  2.5585808753967285\n","tensor([[9.9999e-01, 2.7860e-07, 8.4380e-06, 8.2094e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  180  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.704437732696533\n","Time for preprocessing :  0.11075091361999512\n","Time for training :  2.747816801071167\n","tensor([[2.3842e-04, 4.0340e-08, 9.9972e-01, 4.4764e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  181  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.038382530212402\n","Time for preprocessing :  0.1248927116394043\n","Time for training :  3.0949156284332275\n","tensor([[9.9989e-01, 1.0598e-04, 7.9432e-07, 7.7354e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  182  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.022170782089233\n","Time for preprocessing :  0.0873415470123291\n","Time for training :  2.1586718559265137\n","tensor([[4.5155e-08, 3.9891e-06, 6.9972e-04, 9.9930e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  183  Loss =  tensor(0.7442, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.426160097122192\n","Time for preprocessing :  0.12109732627868652\n","Time for training :  3.443664789199829\n","tensor([[7.9407e-01, 8.2464e-07, 2.0592e-01, 1.4144e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  184  Loss =  tensor(1.4881, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.118235111236572\n","Time for preprocessing :  0.0935523509979248\n","Time for training :  2.540032148361206\n","tensor([[9.9883e-01, 7.2041e-04, 4.5058e-04, 6.6407e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  185  Loss =  tensor(0.7445, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.7475426197052\n","Time for preprocessing :  0.01907491683959961\n","Time for preprocessing :  0.09202957153320312\n","Time for training :  2.2221174240112305\n","tensor([[9.5751e-09, 1.0000e+00, 2.0739e-13, 7.5666e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  187  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.810722827911377\n","Time for preprocessing :  0.0944828987121582\n","Time for training :  2.3775439262390137\n","tensor([[9.9967e-01, 2.8728e-06, 3.3140e-04, 2.6664e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  188  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.26563024520874\n","Time for preprocessing :  0.09166884422302246\n","Time for training :  2.213343858718872\n","tensor([[6.6610e-02, 7.1978e-07, 9.3339e-01, 7.9698e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  189  Loss =  tensor(0.7915, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.578690767288208\n","Time for preprocessing :  0.07326245307922363\n","Time for training :  1.9266314506530762\n","tensor([[3.8244e-04, 1.3643e-08, 9.9961e-01, 6.0916e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  190  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.6901867389678955\n","Time for preprocessing :  0.11990189552307129\n","Time for training :  3.1074225902557373\n","tensor([[1.2321e-08, 1.6456e-06, 2.1532e-03, 9.9785e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  191  Loss =  tensor(0.7452, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.74959397315979\n","Time for preprocessing :  0.0731360912322998\n","Time for training :  1.8947727680206299\n","tensor([[9.9967e-01, 2.3685e-04, 9.1684e-05, 7.3059e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  192  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  3.944730758666992\n","Time for preprocessing :  0.11893320083618164\n","Time for training :  3.5110106468200684\n","tensor([[4.4168e-11, 4.5304e-08, 5.6749e-06, 9.9999e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  193  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.602402925491333\n","Time for preprocessing :  0.14695310592651367\n","Time for training :  3.1115379333496094\n","tensor([[7.4654e-06, 5.7440e-10, 9.9996e-01, 3.1406e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  194  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.348352432250977\n","Time for preprocessing :  0.10351824760437012\n","Time for training :  2.348707914352417\n","tensor([[1.5326e-13, 1.3706e-08, 5.2280e-06, 9.9999e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  195  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.981034517288208\n","Time for preprocessing :  0.10247468948364258\n","Time for training :  2.6176798343658447\n","tensor([[2.6182e-09, 9.9661e-01, 1.4576e-10, 3.3928e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  196  Loss =  tensor(0.7460, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.092497825622559\n","Time for preprocessing :  0.13159608840942383\n","Time for training :  3.706038236618042\n","tensor([[1.9569e-10, 1.9813e-04, 3.6414e-07, 9.9980e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  197  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.321436405181885\n","Time for preprocessing :  0.10433506965637207\n","Time for training :  2.364699602127075\n","tensor([[1.2707e-06, 9.0064e-01, 1.3011e-06, 9.9357e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  198  Loss =  tensor(0.8160, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.164260625839233\n","Time for preprocessing :  0.0952310562133789\n","Time for training :  2.2115366458892822\n","tensor([[7.2095e-07, 9.9916e-01, 6.2929e-09, 8.3713e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  199  Loss =  tensor(0.7443, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.317516803741455\n","Time for preprocessing :  0.14083623886108398\n","Time for training :  3.382887840270996\n","tensor([[2.2099e-08, 9.9151e-01, 3.7116e-10, 8.4942e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  200  Loss =  tensor(0.7496, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.298835277557373\n","Epoch 7/10,Training Accuracy: 0.9494949494949495\n","Time for preprocessing :  0.22230219841003418\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["Time for training :  2.84302020072937\n","tensor([[6.8328e-03, 1.5102e-07, 9.9317e-01, 1.6234e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  201  Loss =  tensor(0.7485, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.605087041854858\n","Time for preprocessing :  0.0859076976776123\n","Time for training :  2.679757833480835\n","tensor([[2.8090e-03, 9.4848e-01, 9.9618e-05, 4.8614e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  202  Loss =  tensor(0.7804, grad_fn=<DivBackward1>)\n","Time for optimisation :  8.308940410614014\n","Time for preprocessing :  0.1522693634033203\n","Time for preprocessing :  0.47844648361206055\n","Time for training :  5.492363214492798\n","tensor([[9.9997e-01, 1.1790e-05, 1.9839e-05, 2.7353e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  204  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  6.382918119430542\n","Time for preprocessing :  0.24578428268432617\n","Time for training :  3.521634340286255\n","tensor([[7.0164e-05, 9.9481e-01, 1.1848e-04, 4.9976e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  205  Loss =  tensor(0.7473, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.979615211486816\n","Time for preprocessing :  0.10086250305175781\n","Time for training :  2.5752480030059814\n","tensor([[4.2366e-08, 9.9992e-01, 5.6999e-11, 8.4251e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  206  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.810303211212158\n","Time for preprocessing :  0.09017395973205566\n","Time for training :  2.2292466163635254\n","tensor([[1.4039e-07, 2.9882e-09, 1.0000e+00, 4.0545e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  207  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.071807384490967\n","Time for preprocessing :  0.16332745552062988\n","Time for training :  1.6151680946350098\n","tensor([[5.7136e-06, 9.9996e-01, 4.1230e-10, 3.4734e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  208  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.936365365982056\n","Time for preprocessing :  0.11745285987854004\n","Time for training :  2.9706385135650635\n","tensor([[1.3496e-04, 9.8562e-01, 9.1448e-08, 1.4243e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  209  Loss =  tensor(0.7538, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.83661150932312\n","Time for preprocessing :  0.07923412322998047\n","Time for training :  2.0874388217926025\n","tensor([[1.0249e-06, 3.3161e-11, 9.9987e-01, 1.2431e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  210  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.30765438079834\n","Time for preprocessing :  0.144639253616333\n","Time for training :  2.541426658630371\n","tensor([[1.0000e+00, 4.2706e-07, 7.0446e-07, 3.4317e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  211  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.046468019485474\n","Time for preprocessing :  0.1087188720703125\n","Time for training :  2.279141902923584\n","tensor([[3.8717e-08, 9.9811e-01, 6.0159e-10, 1.8948e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  212  Loss =  tensor(0.7450, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.427177906036377\n","Time for preprocessing :  0.13414692878723145\n","Time for training :  2.216026782989502\n","tensor([[1.0698e-04, 9.9989e-01, 8.0057e-10, 7.9702e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  213  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.392330884933472\n","Time for preprocessing :  0.19086146354675293\n","Time for training :  2.0381827354431152\n","tensor([[9.9905e-01, 9.5139e-04, 9.4437e-07, 8.6282e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  214  Loss =  tensor(0.7443, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.301915168762207\n","Time for preprocessing :  0.0869441032409668\n","Time for training :  1.8008015155792236\n","tensor([[9.9995e-01, 5.2258e-05, 3.7195e-09, 4.8747e-12]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  215  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.345656394958496\n","Time for preprocessing :  0.07374000549316406\n","Time for training :  1.8566608428955078\n","tensor([[2.8530e-04, 1.7067e-02, 1.6530e-01, 8.1735e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  216  Loss =  tensor(0.8804, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.894723415374756\n","Time for preprocessing :  0.115020751953125\n","Time for training :  2.5360970497131348\n","tensor([[9.9952e-01, 1.0813e-05, 4.6865e-04, 6.8541e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  217  Loss =  tensor(0.7440, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.011409282684326\n","Time for preprocessing :  0.061289072036743164\n","Time for training :  1.440648078918457\n","tensor([[9.9617e-01, 3.7872e-03, 3.9061e-05, 1.0960e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  218  Loss =  tensor(0.7463, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.251455068588257\n","Time for preprocessing :  0.18563413619995117\n","Time for training :  5.152429819107056\n","tensor([[9.9198e-01, 4.1895e-08, 8.0198e-03, 4.1502e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  219  Loss =  tensor(1.7333, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.195470571517944\n","Time for preprocessing :  1.9449586868286133\n","Time for training :  1.6231281757354736\n","tensor([[8.5343e-09, 1.0000e+00, 5.9122e-13, 6.7838e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  220  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.056647539138794\n","Time for preprocessing :  2.4668619632720947\n","Time for training :  3.3250367641448975\n","tensor([[2.1690e-12, 3.9060e-06, 8.0936e-08, 1.0000e+00]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  221  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.446202039718628\n","Time for preprocessing :  1.4490327835083008\n","Time for training :  1.4993996620178223\n","tensor([[1.6636e-15, 1.2315e-07, 2.5346e-09, 1.0000e+00]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  222  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.331474542617798\n","Time for preprocessing :  1.4844882488250732\n","Time for training :  1.4960896968841553\n","tensor([[9.9997e-01, 2.1851e-07, 2.9534e-05, 1.8865e-12]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  223  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.001412391662598\n","Time for preprocessing :  1.4259779453277588\n","Time for training :  2.9660873413085938\n","tensor([[2.8919e-08, 1.0000e+00, 2.0738e-12, 1.1133e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  224  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.227080821990967\n","Time for preprocessing :  1.9099977016448975\n","Time for training :  1.9257118701934814\n","tensor([[2.6872e-09, 7.7286e-05, 1.7530e-04, 9.9975e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  225  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.6981565952301025\n","Time for preprocessing :  2.218271493911743\n","Time for training :  3.72369122505188\n","tensor([[4.8560e-09, 1.4416e-02, 3.1014e-04, 9.8527e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  226  Loss =  tensor(0.7540, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.089129686355591\n","Time for preprocessing :  1.453312635421753\n","Time for training :  2.449613332748413\n","tensor([[2.1508e-06, 9.9994e-01, 1.7312e-09, 5.7777e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  227  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.3248937129974365\n","Time for preprocessing :  1.9835927486419678\n","Time for training :  2.311267137527466\n","tensor([[1.1036e-03, 9.9889e-01, 1.5933e-07, 5.1153e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  228  Loss =  tensor(0.7444, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.429491996765137\n","Time for preprocessing :  1.012511968612671\n","Time for training :  1.4868359565734863\n","tensor([[9.9999e-01, 5.0310e-06, 4.7046e-07, 1.2641e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  229  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.7752156257629395\n","Time for preprocessing :  3.6421825885772705\n","Time for training :  5.9316418170928955\n","tensor([[8.2431e-03, 1.0319e-08, 9.9173e-01, 2.1938e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  230  Loss =  tensor(0.7495, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.153864860534668\n","Time for preprocessing :  1.5189006328582764\n","Time for training :  2.374772787094116\n","tensor([[1.0802e-05, 5.0535e-04, 6.8373e-04, 9.9880e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  231  Loss =  tensor(0.7445, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.4888916015625\n","Time for preprocessing :  1.5992851257324219\n","Time for training :  1.3567442893981934\n","tensor([[1.0000e+00, 7.1802e-09, 1.0720e-07, 1.4903e-14]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  232  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.483781814575195\n","Time for preprocessing :  1.4370794296264648\n","Time for training :  1.6173882484436035\n","tensor([[1.2578e-06, 9.7965e-11, 9.9999e-01, 1.2979e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  233  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.718291521072388\n","Time for preprocessing :  1.7619688510894775\n","Time for training :  2.3852574825286865\n","tensor([[7.1689e-06, 5.9332e-11, 9.9999e-01, 3.1046e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  234  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.458179712295532\n","Time for preprocessing :  1.1995172500610352\n","Time for training :  1.4942865371704102\n","tensor([[9.9912e-01, 3.4132e-06, 8.8102e-04, 1.3841e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  235  Loss =  tensor(0.7443, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.636778116226196\n","Time for preprocessing :  1.804795265197754\n","Time for training :  1.9687538146972656\n","tensor([[1.0000e+00, 1.7698e-06, 4.8520e-07, 1.0292e-14]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  236  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.053897380828857\n","Time for preprocessing :  2.081228256225586\n","Time for training :  1.7405376434326172\n","tensor([[4.7596e-10, 4.8007e-05, 9.8861e-07, 9.9995e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  237  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.1647117137908936\n","Time for preprocessing :  3.1904382705688477\n","Time for training :  5.147252321243286\n","tensor([[2.5729e-11, 6.7307e-05, 5.1644e-05, 9.9988e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  238  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.707414865493774\n","Time for preprocessing :  1.7538714408874512\n","Time for training :  1.7447433471679688\n","tensor([[9.9914e-01, 1.9876e-07, 8.5879e-04, 5.0797e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  239  Loss =  tensor(0.7443, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.461867332458496\n","Time for preprocessing :  2.2896673679351807\n","Time for training :  2.772916555404663\n","tensor([[0.0360, 0.0011, 0.9614, 0.0015]], grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  240  Loss =  tensor(0.7711, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.098536014556885\n","Time for preprocessing :  1.2205328941345215\n","Time for training :  3.218282461166382\n","tensor([[4.2971e-07, 9.9911e-01, 5.0185e-08, 8.9387e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  241  Loss =  tensor(0.7443, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.741009473800659\n","Time for preprocessing :  1.6904141902923584\n","Time for training :  1.7321765422821045\n","tensor([[5.5577e-08, 1.0000e+00, 3.7096e-12, 4.7617e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  242  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.1917736530303955\n","Time for preprocessing :  1.4547955989837646\n","Time for training :  1.0274004936218262\n","tensor([[9.9952e-01, 2.8939e-06, 4.7585e-04, 9.1970e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  243  Loss =  tensor(0.7440, grad_fn=<DivBackward1>)\n","Time for optimisation :  6.459366321563721\n","Time for preprocessing :  1.4953365325927734\n","Time for training :  3.542010545730591\n","tensor([[2.0481e-06, 1.0000e+00, 1.8581e-11, 1.2447e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  244  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  7.104875564575195\n","Time for preprocessing :  1.6368224620819092\n","Time for training :  4.306152582168579\n","tensor([[6.4202e-09, 1.4973e-12, 1.0000e+00, 8.0088e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  245  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  8.760050773620605\n","Time for preprocessing :  1.9744460582733154\n","Time for training :  4.184598445892334\n","tensor([[2.1631e-07, 9.4036e-01, 2.7504e-07, 5.9642e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  246  Loss =  tensor(0.7864, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.951528549194336\n","Time for preprocessing :  3.655089855194092\n","Time for training :  5.616415739059448\n","tensor([[1.9425e-12, 3.3436e-05, 3.6054e-08, 9.9997e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  247  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.612383127212524\n","Time for preprocessing :  2.3401052951812744\n","Time for training :  2.780024290084839\n","tensor([[9.7292e-13, 5.3946e-06, 1.3175e-07, 9.9999e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  248  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.63682222366333\n","Time for preprocessing :  1.8922512531280518\n","Time for training :  2.9496357440948486\n","tensor([[2.2862e-07, 9.7645e-01, 9.7670e-10, 2.3550e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  249  Loss =  tensor(1.7132, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.365656852722168\n","Time for preprocessing :  1.5913991928100586\n","Time for training :  1.0794024467468262\n","tensor([[9.9983e-01, 2.4154e-05, 1.4615e-04, 2.3551e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  250  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.473010778427124\n","Time for preprocessing :  3.360102653503418\n","Time for training :  5.993243217468262\n","tensor([[3.2958e-07, 2.8748e-12, 1.0000e+00, 3.3546e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  251  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.85668420791626\n","Time for preprocessing :  1.613208532333374\n","Time for training :  2.196162223815918\n","tensor([[2.0572e-05, 3.4494e-11, 9.9998e-01, 1.0340e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  252  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.776495695114136\n","Time for preprocessing :  1.266047477722168\n","Time for training :  1.589097499847412\n","tensor([[9.9995e-01, 3.0307e-05, 1.5768e-05, 1.0270e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  253  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.816630601882935\n","Time for preprocessing :  1.739762306213379\n","Time for training :  2.481243848800659\n","tensor([[4.5552e-11, 2.1748e-04, 8.1081e-08, 9.9978e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  254  Loss =  tensor(1.7436, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.709299802780151\n","Time for preprocessing :  1.7374460697174072\n","Time for training :  2.449946165084839\n","tensor([[1.3518e-06, 1.0000e+00, 7.9657e-11, 7.3969e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  255  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.742568254470825\n","Time for preprocessing :  1.155785322189331\n","Time for training :  2.0829854011535645\n","tensor([[8.6645e-05, 9.9974e-01, 1.4591e-10, 1.6863e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  256  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.454458713531494\n","Time for preprocessing :  1.7171003818511963\n","Time for training :  2.5062873363494873\n","tensor([[3.3967e-11, 1.0778e-05, 1.0324e-06, 9.9999e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  257  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.023234844207764\n","Time for preprocessing :  2.173074722290039\n","Time for training :  2.3171887397766113\n","tensor([[2.6586e-13, 6.6204e-06, 8.4072e-08, 9.9999e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  258  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.556514501571655\n","Time for preprocessing :  1.545651912689209\n","Time for training :  3.0640294551849365\n","tensor([[9.9253e-01, 7.4723e-03, 5.3821e-10, 3.8798e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  259  Loss =  tensor(0.7489, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.464976072311401\n","Time for preprocessing :  1.7647171020507812\n","Time for training :  2.260249376296997\n","tensor([[9.9998e-01, 1.0037e-05, 1.3284e-05, 4.3609e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  260  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  3.9736037254333496\n","Time for preprocessing :  2.561100482940674\n","Time for training :  4.364792346954346\n","tensor([[2.8981e-07, 4.6006e-08, 9.9430e-01, 5.7038e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  261  Loss =  tensor(0.7477, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.457968473434448\n","Time for preprocessing :  1.4175171852111816\n","Time for training :  2.204671859741211\n","tensor([[9.9985e-01, 1.5161e-04, 2.7891e-12, 4.0843e-16]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  262  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.34538722038269\n","Time for preprocessing :  1.0991065502166748\n","Time for training :  1.500359296798706\n","tensor([[3.4806e-06, 3.4923e-10, 9.9999e-01, 4.2093e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  263  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.597341775894165\n","Time for preprocessing :  1.8855466842651367\n","Time for training :  2.2140369415283203\n","tensor([[7.2545e-07, 4.5249e-07, 9.9870e-01, 1.2949e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  264  Loss =  tensor(0.7446, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.421549081802368\n","Time for preprocessing :  1.544274091720581\n","Time for training :  2.9972262382507324\n","tensor([[1.9771e-08, 1.0000e+00, 1.6628e-12, 1.8514e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  265  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.5943357944488525\n","Time for preprocessing :  1.1103947162628174\n","Time for training :  2.0096914768218994\n","tensor([[2.1672e-08, 6.7607e-01, 5.3302e-07, 3.2393e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  266  Loss =  tensor(1.0008, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.186892986297607\n","Time for preprocessing :  3.012606620788574\n","Time for training :  4.505504131317139\n","tensor([[3.0309e-09, 3.8541e-04, 1.1188e-04, 9.9950e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  267  Loss =  tensor(0.7440, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.739941120147705\n","Time for preprocessing :  1.5433990955352783\n","Time for training :  2.444974422454834\n","tensor([[9.9964e-01, 3.5743e-04, 1.3926e-08, 8.3240e-13]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  268  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.448163986206055\n","Time for preprocessing :  1.8446266651153564\n","Time for training :  2.37625789642334\n","tensor([[1.2417e-07, 1.0000e+00, 6.7386e-16, 1.1389e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  269  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.98593282699585\n","Time for preprocessing :  1.756192684173584\n","Time for training :  2.2999000549316406\n","tensor([[6.3771e-07, 1.0000e+00, 2.2014e-09, 3.5366e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  270  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  3.9684369564056396\n","Time for preprocessing :  2.0030863285064697\n","Time for training :  2.4880847930908203\n","tensor([[9.5935e-04, 5.0831e-08, 9.9904e-01, 4.1011e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  271  Loss =  tensor(0.7443, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.614905834197998\n","Time for preprocessing :  1.1253836154937744\n","Time for training :  1.9741666316986084\n","tensor([[1.1630e-06, 9.9454e-01, 1.4729e-07, 5.4541e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  272  Loss =  tensor(0.7475, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.629842758178711\n","Time for preprocessing :  1.2405102252960205\n","Time for training :  1.7302160263061523\n","tensor([[9.9991e-01, 9.2347e-05, 6.1647e-08, 1.4921e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  273  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.312370300292969\n","Time for preprocessing :  3.044656753540039\n","Time for training :  3.6722962856292725\n","tensor([[1.9508e-10, 5.7459e-04, 1.7481e-05, 9.9941e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  274  Loss =  tensor(0.7441, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.370507478713989\n","Time for preprocessing :  3.4128055572509766\n","Time for training :  6.523394823074341\n","tensor([[1.1826e-02, 1.1416e-06, 9.8817e-01, 2.3438e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  275  Loss =  tensor(0.7520, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.290672063827515\n","Time for preprocessing :  1.6451878547668457\n","Time for training :  1.8435680866241455\n","tensor([[5.0251e-08, 1.0000e+00, 5.7384e-11, 3.2270e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  276  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.451492786407471\n","Time for preprocessing :  1.6703574657440186\n","Time for training :  2.6028645038604736\n","tensor([[1.2366e-11, 5.3431e-05, 7.9481e-07, 9.9995e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  277  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.97440505027771\n","Time for preprocessing :  2.7441837787628174\n","Time for training :  3.503457546234131\n","tensor([[1.9044e-04, 9.8746e-01, 3.8693e-06, 1.2342e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  278  Loss =  tensor(0.7525, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.043135643005371\n","Time for preprocessing :  1.0949044227600098\n","Time for training :  2.7490108013153076\n","tensor([[5.6071e-08, 9.9963e-01, 3.9409e-10, 3.7415e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  279  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  6.35314416885376\n","Time for preprocessing :  0.6134274005889893\n","Time for preprocessing :  1.9187054634094238\n","Time for training :  1.7780275344848633\n","tensor([[1.3219e-06, 1.3760e-10, 1.0000e+00, 6.2794e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  281  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.407030344009399\n","Time for preprocessing :  0.9854373931884766\n","Time for training :  1.8370635509490967\n","tensor([[1.0000e+00, 1.1906e-06, 6.8272e-07, 8.0105e-15]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  282  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.292626619338989\n","Time for preprocessing :  1.9558191299438477\n","Time for training :  1.6865935325622559\n","tensor([[9.2848e-01, 7.1521e-02, 4.9503e-07, 5.6739e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  283  Loss =  tensor(0.7951, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.456370115280151\n","Time for preprocessing :  1.8709063529968262\n","Time for training :  2.3859670162200928\n","tensor([[7.8725e-08, 1.1363e-03, 1.2081e-04, 9.9874e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  284  Loss =  tensor(0.7445, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.401453495025635\n","Time for preprocessing :  1.2543303966522217\n","Time for training :  2.0327539443969727\n","tensor([[3.2763e-03, 4.3064e-05, 9.9602e-01, 6.6534e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  285  Loss =  tensor(1.7392, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.597584962844849\n","Time for preprocessing :  0.8865833282470703\n","Time for training :  0.6705625057220459\n","tensor([[5.9732e-02, 8.7143e-06, 9.4025e-01, 7.6558e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  286  Loss =  tensor(0.7865, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.932716608047485\n","Time for preprocessing :  2.026660442352295\n","Time for training :  2.1957345008850098\n","tensor([[9.9983e-01, 1.6244e-04, 3.9377e-06, 1.2929e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  287  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.843973398208618\n","Time for preprocessing :  1.5920217037200928\n","Time for training :  2.7802207469940186\n","tensor([[1.9428e-04, 9.9980e-01, 2.7633e-09, 2.1084e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  288  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.662734746932983\n","Time for preprocessing :  1.5110392570495605\n","Time for training :  1.697011947631836\n","tensor([[9.9994e-01, 5.9688e-05, 9.4745e-08, 8.8431e-12]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  289  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.1836347579956055\n","Time for preprocessing :  1.9469773769378662\n","Time for training :  2.5754690170288086\n","tensor([[9.9998e-01, 7.5820e-06, 1.1670e-05, 1.9978e-13]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  290  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  3.8816473484039307\n","Time for preprocessing :  0.9405286312103271\n","Time for training :  1.2712593078613281\n","tensor([[9.9670e-01, 3.2932e-03, 2.1400e-06, 1.1136e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  291  Loss =  tensor(0.7460, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.108444452285767\n","Time for preprocessing :  1.8183314800262451\n","Time for training :  3.757413387298584\n","tensor([[1.3498e-06, 9.9975e-01, 2.6401e-08, 2.4689e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  292  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.510851860046387\n","Time for preprocessing :  1.6684901714324951\n","Time for training :  1.8414456844329834\n","tensor([[1.8884e-13, 5.3304e-03, 1.1568e-07, 9.9467e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  293  Loss =  tensor(0.7474, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.034292459487915\n","Time for preprocessing :  1.7814207077026367\n","Time for training :  2.839860200881958\n","tensor([[2.0746e-07, 1.3171e-11, 1.0000e+00, 9.7123e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  294  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.526590824127197\n","Time for preprocessing :  2.2345104217529297\n","Time for training :  2.212779998779297\n","tensor([[2.2843e-06, 9.9996e-01, 1.3156e-08, 3.8760e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  295  Loss =  tensor(1.7436, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.251082897186279\n","Time for preprocessing :  1.7963008880615234\n","Time for training :  2.3026669025421143\n","tensor([[3.7685e-03, 9.9623e-01, 1.1518e-07, 5.1092e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  296  Loss =  tensor(0.7463, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.276262998580933\n","Time for preprocessing :  0.9257731437683105\n","Time for training :  1.4129424095153809\n","tensor([[1.0660e-05, 9.9999e-01, 1.4922e-11, 1.9787e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  297  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.990071058273315\n","Time for preprocessing :  2.001544237136841\n","Time for training :  3.502476453781128\n","tensor([[2.2233e-10, 5.2071e-02, 9.5842e-07, 9.4793e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  298  Loss =  tensor(0.7809, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.742363214492798\n","Time for preprocessing :  1.9474208354949951\n","Time for training :  2.2000691890716553\n","tensor([[5.4753e-07, 6.1585e-01, 1.5389e-04, 3.8400e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  299  Loss =  tensor(1.2874, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.697750091552734\n","Time for preprocessing :  1.8407764434814453\n","Time for training :  3.2360947132110596\n","tensor([[9.7467e-01, 2.5069e-02, 2.5666e-04, 1.0381e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  300  Loss =  tensor(0.7616, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.38059401512146\n","Epoch 7/10,Training Accuracy: 0.9441624365482234\n","Time for preprocessing :  1.132272720336914\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["Time for training :  2.03256893157959\n","tensor([[1.0000e+00, 9.9773e-07, 7.2065e-09, 2.8256e-13]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  301  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.41406774520874\n","Time for preprocessing :  2.3811473846435547\n","Time for training :  3.8213083744049072\n","tensor([[1.6802e-04, 2.1555e-02, 5.5822e-03, 9.7269e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  302  Loss =  tensor(0.7630, grad_fn=<DivBackward1>)\n","Time for optimisation :  10.474652290344238\n","Time for preprocessing :  1.6172740459442139\n","Time for training :  1.3484625816345215\n","tensor([[9.9841e-01, 1.0362e-03, 5.5583e-04, 1.6722e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  303  Loss =  tensor(0.7448, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.001614809036255\n","Time for preprocessing :  2.3829989433288574\n","Time for training :  7.146835803985596\n","tensor([[9.9844e-06, 9.9959e-01, 4.3457e-06, 3.9915e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  304  Loss =  tensor(0.7440, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.149014949798584\n","Time for preprocessing :  1.736725091934204\n","Time for training :  2.5505149364471436\n","tensor([[9.9985e-01, 1.4707e-04, 6.4176e-07, 5.7217e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  305  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.5867018699646\n","Time for preprocessing :  1.563575267791748\n","Time for training :  2.5633959770202637\n","tensor([[7.3105e-05, 9.9885e-01, 3.1743e-07, 1.0781e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  306  Loss =  tensor(0.7445, grad_fn=<DivBackward1>)\n","Time for optimisation :  11.096435546875\n","Time for preprocessing :  1.7169020175933838\n","Time for training :  2.3265302181243896\n","tensor([[9.9712e-01, 2.8626e-03, 1.3919e-05, 3.4871e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  307  Loss =  tensor(0.7457, grad_fn=<DivBackward1>)\n","Time for optimisation :  7.916274785995483\n","Time for preprocessing :  1.501718521118164\n","Time for training :  2.3880198001861572\n","tensor([[9.4188e-01, 5.8120e-02, 2.9625e-08, 2.2157e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  308  Loss =  tensor(0.7853, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.462028503417969\n","Time for preprocessing :  1.0792908668518066\n","Time for training :  1.8271734714508057\n","tensor([[7.8724e-07, 9.9497e-01, 4.8078e-08, 5.0296e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  309  Loss =  tensor(0.7472, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.3000757694244385\n","Time for preprocessing :  0.9234809875488281\n","Time for training :  1.9453001022338867\n","tensor([[9.9999e-01, 1.2689e-06, 1.0095e-05, 6.8281e-12]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  310  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.283655405044556\n","Time for preprocessing :  2.143397092819214\n","Time for training :  2.397855758666992\n","tensor([[3.4479e-04, 9.6926e-01, 1.2099e-03, 2.9183e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  311  Loss =  tensor(0.7654, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.465592384338379\n","Time for preprocessing :  1.8616993427276611\n","Time for training :  3.115811824798584\n","tensor([[7.9583e-05, 3.2064e-12, 9.9992e-01, 1.0355e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  312  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.649854898452759\n","Time for preprocessing :  2.022090435028076\n","Time for training :  1.9479503631591797\n","tensor([[1.0998e-04, 9.9158e-01, 1.5709e-05, 8.2901e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  313  Loss =  tensor(0.7496, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.873781442642212\n","Time for preprocessing :  2.505728244781494\n","Time for training :  2.5732057094573975\n","tensor([[1.1624e-08, 2.0086e-12, 9.9998e-01, 2.3185e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  314  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.674337387084961\n","Time for preprocessing :  4.00617790222168\n","Time for training :  5.911428213119507\n","tensor([[2.8692e-03, 2.1005e-10, 9.9713e-01, 2.4340e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  315  Loss =  tensor(0.7457, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.3761091232299805\n","Time for preprocessing :  0.9408016204833984\n","Time for training :  1.2741162776947021\n","tensor([[9.9997e-01, 8.4766e-07, 3.2337e-05, 3.0519e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  316  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.137350082397461\n","Time for preprocessing :  1.536379098892212\n","Time for training :  1.5872535705566406\n","tensor([[1.0000e+00, 1.5099e-07, 1.9859e-08, 3.5699e-15]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  317  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.352571725845337\n","Time for preprocessing :  1.0612826347351074\n","Time for training :  2.2644166946411133\n","tensor([[1.0000e+00, 7.0975e-09, 3.9554e-07, 4.4846e-15]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  318  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.9125449657440186\n","Time for preprocessing :  1.8224854469299316\n","Time for training :  1.851550817489624\n","tensor([[1.4089e-12, 1.7969e-07, 1.1993e-08, 1.0000e+00]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  319  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.487974166870117\n","Time for preprocessing :  1.9840013980865479\n","Time for training :  2.006596088409424\n","tensor([[9.6827e-01, 1.8581e-04, 3.1517e-02, 2.3538e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  320  Loss =  tensor(0.7661, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.386200904846191\n","Time for preprocessing :  2.2279679775238037\n","Time for training :  3.5723330974578857\n","tensor([[6.4453e-02, 8.8475e-01, 2.3173e-04, 5.0568e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  321  Loss =  tensor(0.8274, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.090950965881348\n","Time for preprocessing :  2.019385576248169\n","Time for training :  3.437852621078491\n","tensor([[1.6110e-07, 3.7400e-03, 8.6447e-04, 9.9540e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  322  Loss =  tensor(0.7469, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.590743064880371\n","Time for preprocessing :  1.1050786972045898\n","Time for training :  1.8282105922698975\n","tensor([[2.8835e-08, 9.9988e-01, 1.7497e-10, 1.2381e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  323  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.408522844314575\n","Time for preprocessing :  1.360778570175171\n","Time for training :  3.342930555343628\n","tensor([[9.9982e-01, 5.3309e-06, 1.7901e-04, 1.5413e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  324  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.1490373611450195\n","Time for preprocessing :  2.5426952838897705\n","Time for training :  3.4200398921966553\n","tensor([[1.4686e-05, 9.9928e-01, 8.4860e-08, 7.0396e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  325  Loss =  tensor(0.7442, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.2653186321258545\n","Time for preprocessing :  2.309274673461914\n","Time for training :  3.401442289352417\n","tensor([[4.7217e-09, 4.9739e-05, 2.1347e-03, 9.9782e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  326  Loss =  tensor(0.7452, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.147005081176758\n","Time for preprocessing :  1.6513051986694336\n","Time for training :  1.1109414100646973\n","tensor([[9.9591e-01, 2.9049e-08, 4.0870e-03, 3.1471e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  327  Loss =  tensor(0.7465, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.223794937133789\n","Time for preprocessing :  3.7650668621063232\n","Time for training :  7.042009592056274\n","tensor([[1.4663e-15, 9.0349e-09, 1.7454e-07, 1.0000e+00]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  328  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.56644606590271\n","Time for preprocessing :  1.826369047164917\n","Time for training :  2.212751626968384\n","tensor([[4.5232e-13, 8.6427e-08, 1.3618e-05, 9.9999e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  329  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.820072412490845\n","Time for preprocessing :  1.6083626747131348\n","Time for training :  2.546050786972046\n","tensor([[9.9996e-01, 3.8029e-05, 5.3029e-07, 3.0914e-12]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  330  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.580718278884888\n","Time for preprocessing :  2.4319264888763428\n","Time for training :  3.5161399841308594\n","tensor([[2.0521e-06, 9.9343e-01, 1.6671e-07, 6.5650e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  331  Loss =  tensor(0.7483, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.521477460861206\n","Time for preprocessing :  2.186293125152588\n","Time for training :  3.2325875759124756\n","tensor([[2.9624e-06, 9.9827e-01, 6.3594e-07, 1.7255e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  332  Loss =  tensor(0.7449, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.174335479736328\n","Time for preprocessing :  2.5864853858947754\n","Time for training :  4.269550323486328\n","tensor([[5.8642e-06, 6.7149e-07, 9.9387e-01, 6.1279e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  333  Loss =  tensor(0.7480, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.3586084842681885\n","Time for preprocessing :  1.7351202964782715\n","Time for training :  1.8840889930725098\n","tensor([[3.7110e-05, 8.4613e-01, 7.6203e-06, 1.5383e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  334  Loss =  tensor(0.8581, grad_fn=<DivBackward1>)\n","Time for optimisation :  3.932648181915283\n","Time for preprocessing :  3.3778183460235596\n","Time for training :  6.106813907623291\n","tensor([[4.2690e-05, 4.1718e-07, 9.9686e-01, 3.0997e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  335  Loss =  tensor(0.7459, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.903176307678223\n","Time for preprocessing :  1.4362833499908447\n","Time for training :  2.1054580211639404\n","tensor([[9.9973e-01, 2.7053e-04, 1.7490e-07, 6.1754e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  336  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.504618167877197\n","Time for preprocessing :  1.2098548412322998\n","Time for training :  2.5733141899108887\n","tensor([[9.9634e-01, 3.5125e-05, 3.6198e-03, 6.8591e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  337  Loss =  tensor(0.7462, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.107792377471924\n","Time for preprocessing :  1.7563352584838867\n","Time for training :  1.6141972541809082\n","tensor([[1.5544e-05, 9.8008e-01, 1.1726e-07, 1.9903e-02]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  338  Loss =  tensor(0.7577, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.308682441711426\n","Time for preprocessing :  1.4608240127563477\n","Time for training :  2.0667781829833984\n","tensor([[1.0000e+00, 2.6139e-06, 1.3302e-07, 1.6200e-12]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  339  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.457873344421387\n","Time for preprocessing :  1.9328229427337646\n","Time for training :  2.10487961769104\n","tensor([[9.9990e-01, 9.9189e-05, 1.2176e-09, 1.0727e-13]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  340  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.354550123214722\n","Time for preprocessing :  0.8447489738464355\n","Time for training :  1.3609797954559326\n","tensor([[9.9998e-01, 7.1416e-07, 2.3049e-05, 6.0148e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  341  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.408044338226318\n","Time for preprocessing :  1.6553020477294922\n","Time for training :  2.104681968688965\n","tensor([[6.1184e-04, 9.9938e-01, 2.0584e-06, 1.0522e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  342  Loss =  tensor(0.7441, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.230787754058838\n","Time for preprocessing :  1.564283847808838\n","Time for training :  2.2119462490081787\n","tensor([[3.6710e-08, 1.0000e+00, 2.9485e-12, 9.7818e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  343  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.292729139328003\n","Time for preprocessing :  1.6904232501983643\n","Time for training :  3.3031702041625977\n","tensor([[5.9694e-04, 9.9937e-01, 5.3367e-06, 2.6685e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  344  Loss =  tensor(0.7441, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.228287220001221\n","Time for preprocessing :  1.378532886505127\n","Time for training :  2.2032206058502197\n","tensor([[1.0000e+00, 2.5555e-07, 4.5431e-06, 3.3620e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  345  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.226995944976807\n","Time for preprocessing :  1.770965814590454\n","Time for training :  2.866504192352295\n","tensor([[1.0839e-05, 9.7652e-10, 9.9999e-01, 8.9891e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  346  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.142422199249268\n","Time for preprocessing :  1.224128246307373\n","Time for training :  2.2046356201171875\n","tensor([[5.2744e-04, 9.9191e-01, 4.0130e-04, 7.1580e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  347  Loss =  tensor(0.7493, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.993597984313965\n","Time for preprocessing :  2.1923935413360596\n","Time for training :  3.153517961502075\n","tensor([[4.0982e-06, 9.9741e-01, 5.9325e-05, 2.5257e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  348  Loss =  tensor(1.7404, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.420012474060059\n","Time for preprocessing :  2.2281346321105957\n","Time for training :  2.924830675125122\n","tensor([[7.8412e-06, 1.1435e-07, 9.9914e-01, 8.4919e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  349  Loss =  tensor(0.7443, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.297472238540649\n","Time for preprocessing :  1.251077651977539\n","Time for training :  2.0080387592315674\n","tensor([[9.9983e-01, 4.0888e-05, 1.2690e-04, 5.0317e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  350  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.369881629943848\n","Time for preprocessing :  2.8639516830444336\n","Time for training :  2.975257158279419\n","tensor([[1.2972e-03, 9.9870e-01, 3.2563e-07, 3.2783e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  351  Loss =  tensor(0.7446, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.586266994476318\n","Time for preprocessing :  1.542881727218628\n","Time for training :  2.404334783554077\n","tensor([[9.9999e-01, 2.3593e-06, 1.1933e-05, 3.4838e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  352  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.664211750030518\n","Time for preprocessing :  1.4903984069824219\n","Time for training :  1.8250763416290283\n","tensor([[3.4046e-07, 2.1617e-12, 1.0000e+00, 6.8683e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  353  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.219062089920044\n","Time for preprocessing :  1.0852868556976318\n","Time for training :  2.4941349029541016\n","tensor([[5.9756e-06, 9.9999e-01, 1.1039e-11, 3.8633e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  354  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.394518852233887\n","Time for preprocessing :  3.6100871562957764\n","Time for training :  5.147534370422363\n","tensor([[8.5805e-06, 1.9618e-11, 9.9999e-01, 7.5746e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  355  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.652118682861328\n","Time for preprocessing :  2.0615358352661133\n","Time for training :  2.572925567626953\n","tensor([[2.6579e-09, 9.1642e-06, 3.2063e-05, 9.9996e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  356  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.62687087059021\n","Time for preprocessing :  2.3424460887908936\n","Time for training :  3.0557236671447754\n","tensor([[1.0000e+00, 5.9977e-09, 4.0742e-10, 3.7647e-18]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  357  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  6.074003458023071\n","Time for preprocessing :  3.099832057952881\n","Time for training :  3.9778149127960205\n","tensor([[2.1740e-07, 5.8052e-06, 2.1671e-04, 9.9978e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  358  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.268797159194946\n","Time for preprocessing :  1.4063074588775635\n","Time for training :  2.55643630027771\n","tensor([[2.9506e-04, 7.1751e-06, 9.9185e-01, 7.8485e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  359  Loss =  tensor(0.7494, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.335186719894409\n","Time for preprocessing :  1.818638563156128\n","Time for training :  2.2221364974975586\n","tensor([[4.6730e-02, 3.5915e-06, 9.5319e-01, 8.1064e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  360  Loss =  tensor(0.7770, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.275821924209595\n","Time for preprocessing :  2.4298229217529297\n","Time for training :  3.916344404220581\n","tensor([[3.2630e-09, 7.9345e-06, 7.9421e-04, 9.9920e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  361  Loss =  tensor(0.7442, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.2650628089904785\n","Time for preprocessing :  1.9365286827087402\n","Time for training :  2.4944562911987305\n","tensor([[9.9981e-01, 1.8423e-06, 1.8616e-04, 2.2829e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  362  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.757531404495239\n","Time for preprocessing :  1.8420250415802002\n","Time for training :  3.1172051429748535\n","tensor([[4.0197e-08, 1.1938e-02, 7.0095e-06, 9.8806e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  363  Loss =  tensor(0.7521, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.919439792633057\n","Time for preprocessing :  1.2586851119995117\n","Time for training :  1.6210660934448242\n","tensor([[9.9996e-01, 3.9646e-05, 2.3274e-07, 9.2158e-12]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  364  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.249370813369751\n","Time for preprocessing :  2.6693670749664307\n","Time for training :  5.961771011352539\n","tensor([[4.9596e-07, 9.9961e-01, 2.4126e-09, 3.8730e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  365  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.602496147155762\n","Time for preprocessing :  1.2733888626098633\n","Time for training :  1.858982801437378\n","tensor([[4.0630e-06, 9.9993e-01, 1.8726e-11, 6.1332e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  366  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.887195587158203\n","Time for preprocessing :  1.4781270027160645\n","Time for training :  3.243454694747925\n","tensor([[2.2560e-05, 9.9997e-01, 2.9795e-08, 4.4337e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  367  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  6.582432508468628\n","Time for preprocessing :  1.9164400100708008\n","Time for training :  2.586266279220581\n","tensor([[2.7502e-04, 4.5574e-09, 9.9969e-01, 3.2367e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  368  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.211687088012695\n","Time for preprocessing :  2.580153703689575\n","Time for training :  2.928762912750244\n","tensor([[2.3333e-05, 9.9998e-01, 2.6390e-11, 3.4693e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  369  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  12.129399061203003\n","Time for preprocessing :  2.5667221546173096\n","Time for training :  3.8718032836914062\n","tensor([[7.9234e-06, 9.9949e-01, 6.8620e-08, 4.9851e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  370  Loss =  tensor(0.7440, grad_fn=<DivBackward1>)\n","Time for optimisation :  7.29227614402771\n","Time for preprocessing :  1.9271759986877441\n","Time for training :  1.3255095481872559\n","tensor([[9.9998e-01, 1.5913e-05, 1.5332e-06, 9.2209e-10]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  371  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.329111576080322\n","Time for preprocessing :  1.8985071182250977\n","Time for training :  2.737868070602417\n","tensor([[9.9826e-01, 1.0312e-10, 1.7378e-03, 2.2828e-11]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  372  Loss =  tensor(0.7449, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.688438892364502\n","Time for preprocessing :  1.0543863773345947\n","Time for training :  1.780447244644165\n","tensor([[2.2374e-06, 9.9869e-01, 4.4420e-10, 1.3102e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  373  Loss =  tensor(0.7446, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.526277542114258\n","Time for preprocessing :  3.9120655059814453\n","Time for training :  6.170752048492432\n","tensor([[2.5896e-08, 1.0599e-02, 3.1375e-05, 9.8937e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  374  Loss =  tensor(0.7511, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.437323093414307\n","Time for preprocessing :  1.9565856456756592\n","Time for training :  3.645634412765503\n","tensor([[6.1883e-06, 9.9990e-01, 9.3331e-09, 9.1172e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  375  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.754460334777832\n","Time for preprocessing :  3.8952224254608154\n","Time for training :  5.1523191928863525\n","tensor([[1.9732e-07, 2.2751e-02, 1.7262e-02, 9.5999e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  376  Loss =  tensor(0.7720, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.094526529312134\n","Time for preprocessing :  1.2181386947631836\n","Time for training :  2.9707345962524414\n","tensor([[1.0000e+00, 2.4132e-08, 5.8499e-08, 7.5029e-12]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  377  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.791745901107788\n","Time for preprocessing :  0.9664807319641113\n","Time for training :  1.7991266250610352\n","tensor([[1.0937e-06, 9.9391e-01, 7.5177e-07, 6.0871e-03]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  378  Loss =  tensor(0.7479, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.274868011474609\n","Time for preprocessing :  2.1234853267669678\n","Time for training :  3.547548532485962\n","tensor([[8.5537e-06, 6.4936e-03, 6.4185e-02, 9.2931e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  379  Loss =  tensor(0.7945, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.2053422927856445\n","Time for preprocessing :  2.0448567867279053\n","Time for training :  2.0903031826019287\n","tensor([[1.4505e-06, 9.9933e-01, 5.5505e-08, 6.6511e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  380  Loss =  tensor(0.7441, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.722735404968262\n","Time for preprocessing :  2.211346387863159\n","Time for training :  3.550666332244873\n","tensor([[1.4960e-03, 2.7952e-07, 9.9850e-01, 8.0253e-07]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  381  Loss =  tensor(0.7447, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.711601257324219\n","Time for preprocessing :  2.6534769535064697\n","Time for training :  3.9299070835113525\n","tensor([[2.2564e-08, 4.0649e-04, 5.3680e-03, 9.9423e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  382  Loss =  tensor(0.7477, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.236294984817505\n","Time for preprocessing :  0.9101557731628418\n","Time for training :  1.9135301113128662\n","tensor([[1.0000e+00, 3.4325e-09, 3.7704e-07, 2.6621e-14]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  383  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.569823503494263\n","Time for preprocessing :  0.9430274963378906\n","Time for training :  0.6604912281036377\n","tensor([[0.0025, 0.0924, 0.7332, 0.1718]], grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  384  Loss =  tensor(1.5087, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.831831693649292\n","Time for preprocessing :  1.1133263111114502\n","Time for training :  2.5885472297668457\n","tensor([[1.0000e+00, 4.2807e-08, 7.4700e-10, 7.8507e-16]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  385  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.2350170612335205\n","Time for preprocessing :  1.8248305320739746\n","Time for training :  2.1037747859954834\n","tensor([[1.5008e-05, 3.6218e-01, 7.4251e-05, 6.3773e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  386  Loss =  tensor(1.0354, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.759287595748901\n","Time for preprocessing :  3.66422438621521\n","Time for training :  6.016617774963379\n","tensor([[3.2834e-03, 1.6871e-04, 2.9173e-02, 9.6737e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  387  Loss =  tensor(0.7668, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.715390205383301\n","Time for preprocessing :  1.6135129928588867\n","Time for training :  2.0045597553253174\n","tensor([[1.3668e-01, 1.8452e-06, 8.6330e-01, 1.5252e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  388  Loss =  tensor(0.8446, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.701998949050903\n","Time for preprocessing :  1.1147699356079102\n","Time for training :  2.0079333782196045\n","tensor([[9.9971e-01, 2.8666e-04, 1.2390e-09, 4.2071e-13]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  389  Loss =  tensor(0.7439, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.447722673416138\n","Time for preprocessing :  1.6284494400024414\n","Time for training :  1.8227567672729492\n","tensor([[5.5192e-09, 6.8275e-12, 1.0000e+00, 2.3568e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  390  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.613295316696167\n","Time for preprocessing :  1.9757928848266602\n","Time for training :  2.235626697540283\n","tensor([[1.7969e-05, 9.9992e-01, 3.0459e-09, 6.3269e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  391  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.652577638626099\n","Time for preprocessing :  1.1984124183654785\n","Time for training :  1.8271379470825195\n","tensor([[9.9926e-01, 1.4654e-04, 5.9728e-04, 2.1473e-08]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  392  Loss =  tensor(0.7442, grad_fn=<DivBackward1>)\n","Time for optimisation :  11.871210813522339\n","Time for preprocessing :  2.247589111328125\n","Time for training :  3.7318732738494873\n","tensor([[7.3937e-13, 6.8334e-06, 3.3080e-09, 9.9999e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 0., 1.]])\n","Index =  393  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  9.606965065002441\n","Time for preprocessing :  1.735579013824463\n","Time for training :  8.017977476119995\n","tensor([[6.7076e-11, 9.9997e-01, 1.8317e-11, 2.5041e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  394  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  9.0902419090271\n","Time for preprocessing :  0.24443602561950684\n","Time for preprocessing :  2.399012327194214\n","Time for training :  4.81254768371582\n","tensor([[7.5180e-05, 9.9987e-01, 1.1273e-08, 5.1360e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 1., 0., 0.]])\n","Index =  396  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.827416658401489\n","Time for preprocessing :  1.8778464794158936\n","Time for training :  4.882139444351196\n","tensor([[1.1952e-02, 8.9970e-05, 3.5241e-01, 6.3555e-01]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  397  Loss =  tensor(1.3196, grad_fn=<DivBackward1>)\n","Time for optimisation :  9.278640985488892\n","Time for preprocessing :  1.6458518505096436\n","Time for training :  3.066622734069824\n","tensor([[1.0276e-07, 2.7344e-12, 9.9999e-01, 9.3137e-06]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  398  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.128641128540039\n","Time for preprocessing :  1.769930124282837\n","Time for training :  2.5252974033355713\n","tensor([[5.9259e-14, 9.3210e-17, 9.9997e-01, 2.8821e-05]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  399  Loss =  tensor(0.7437, grad_fn=<DivBackward1>)\n","Time for optimisation :  5.072031021118164\n","Time for preprocessing :  2.0048351287841797\n","Time for training :  2.0907514095306396\n","tensor([[3.9172e-05, 1.3584e-08, 9.9980e-01, 1.5736e-04]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[0., 0., 1., 0.]])\n","Index =  400  Loss =  tensor(0.7438, grad_fn=<DivBackward1>)\n","Time for optimisation :  4.532564401626587\n","Epoch 7/10,Training Accuracy: 0.9527027027027027\n","Time for preprocessing :  1.8097689151763916\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["Time for training :  1.3574535846710205\n","tensor([[9.9953e-01, 1.2043e-07, 4.6614e-04, 1.8807e-09]],\n","       grad_fn=<SoftmaxBackward0>) tensor([[1., 0., 0., 0.]])\n","Index =  401  Loss =  tensor(0.7440, grad_fn=<DivBackward1>)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-7344fdb9b10b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m               \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m               \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m               \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 state_steps)\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    312\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# Lastly, switch back to complex view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from sklearn.metrics import roc_auc_score, accuracy_score\n","for epoch in range(last_epoch,num_epochs):\n","    running_loss = 0.0\n","    print(\"Epoch no. \",epoch)\n","    all_labels = []\n","    all_preds = []\n","    for bth_idx in range(last_index+1,len(train_data)):\n","          # Forward pass\n","          start = time.time()\n","          frames,mel,labels = train_dataset.__getitem__(bth_idx)\n","          end = time.time()\n","\n","          print(\"Time for preprocessing : \", end-start)\n","\n","\n","          if len(frames) != 0 :\n","\n","              start = time.time()\n","              outputs = multimodal_model(frames, mel)\n","              end = time.time()\n","\n","              print(\"Time for training : \", end-start)\n","              labels = torch.unsqueeze(labels, dim=0)\n","              print(outputs,labels)\n","              loss = criterion(outputs, labels)\n","              print(\"Index = \",bth_idx,\" Loss = \",loss)\n","              # Backward pass and optimization\n","\n","              start = time.time()\n","              optimizer.zero_grad()\n","              loss.backward()\n","              optimizer.step()\n","              running_loss += loss.item()\n","              end = time.time()\n","              print(\"Time for optimisation : \",  end-start)\n","              _, preds1 = torch.max(outputs, 1)\n","              _, preds2 = torch.max(labels, 1)\n","              all_labels.extend(preds2.cpu().numpy())\n","              all_preds.extend(preds1.cpu().numpy())\n","              # check point\n","              if bth_idx%100 == 0 :\n","                  accuracy = accuracy_score(all_labels, all_preds)\n","                  print(f'Epoch {epoch}/{num_epochs},Training Accuracy: {accuracy}')\n","                  checkpoint = {\n","                      'epoch': epoch,\n","                      'model_state_dict': multimodal_model.state_dict(),\n","                      'optimizer_state_dict': optimizer.state_dict(),\n","                      'loss': loss,\n","                      'bth_idx':bth_idx,\n","                      'train_data' : train_data,\n","                      'test_data':test_data\n","                  }\n","                  torch.save(checkpoint, 'drive/MyDrive/Colab Notebooks/Final_Year_Project/model_reduced_dataset_checkpoint.pth')\n","\n","    last_index = -1\n","    checkpoint = {\n","        'epoch': epoch+1,\n","        'model_state_dict': multimodal_model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': running_loss,\n","        'bth_idx':last_index,\n","        'train_data' : train_data,\n","        'test_data':test_data\n","    }\n","    torch.save(checkpoint, f'drive/MyDrive/Colab Notebooks/Final_Year_Project/model_reduced_dataset_checkpoint_{epoch}.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9YruoYN0cZ8","outputId":"121cda2f-44e0-41d3-c3c1-7b0b8d36d3b5"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["0 0.0\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["1 0.5\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["2 0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["3 0.75\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["4 0.6\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["5 0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["6 0.5714285714285714\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["7 0.625\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["8 0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["9 0.7\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["10 0.7272727272727273\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["11 0.75\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["12 0.7692307692307693\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["13 0.7142857142857143\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["14 0.7333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["15 0.75\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["16 0.7647058823529411\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["17 0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["18 0.7894736842105263\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["19 0.8\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["20 0.7619047619047619\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["21 0.7727272727272727\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["22 0.782608695652174\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["23 0.75\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["24 0.76\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["25 0.7692307692307693\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["26 0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["27 0.7857142857142857\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["28 0.7931034482758621\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["29 0.8\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["30 0.7741935483870968\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["31 0.78125\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["32 0.7575757575757576\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["33 0.7647058823529411\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["34 0.7714285714285715\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["35 0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["36 0.7837837837837838\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["37 0.7894736842105263\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["38 0.7948717948717948\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["39 0.8\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["40 0.8048780487804879\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["41 0.8095238095238095\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["42 0.7906976744186046\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["43 0.7954545454545454\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["44 0.8\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["45 0.8043478260869565\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["46 0.8085106382978723\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["47 0.8125\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["48 0.8163265306122449\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["49 0.82\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["50 0.8235294117647058\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["51 0.8076923076923077\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["52 0.8113207547169812\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["53 0.7962962962962963\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["54 0.8\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["55 0.7857142857142857\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["56 0.7894736842105263\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["57 0.7758620689655172\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["58 0.7796610169491526\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["59 0.7833333333333333\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["60 0.7868852459016393\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["61 0.7903225806451613\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["62 0.7936507936507936\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["63 0.796875\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["64 0.8\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["65 0.7878787878787878\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["66 0.7761194029850746\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["67 0.7794117647058824\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["68 0.782608695652174\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["69 0.7714285714285715\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["70 0.7746478873239436\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["71 0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["72 0.7808219178082192\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["73 0.7837837837837838\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["74 0.7866666666666666\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["75 0.7894736842105263\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["76 0.7792207792207793\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["77 0.782051282051282\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["78 0.7848101265822784\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["79 0.775\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["80 0.7777777777777778\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["81 0.7804878048780488\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["82 0.7831325301204819\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["83 0.7857142857142857\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["84 0.7764705882352941\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["85 0.7790697674418605\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["86 0.7816091954022989\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["87 0.7727272727272727\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["88 0.7640449438202247\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["89 0.7666666666666667\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["90 0.7582417582417582\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["91 0.7608695652173914\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["92 0.7634408602150538\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["93 0.7553191489361702\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["94 0.7578947368421053\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["95 0.75\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["96 0.7422680412371134\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["97 0.7346938775510204\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["98 0.7373737373737373\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["99 0.74\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["100 0.7425742574257426\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["101 0.7352941176470589\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["102 0.7378640776699029\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["103 0.7403846153846154\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["104 0.7333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["105 0.7358490566037735\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["106 0.7383177570093458\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["107 0.7314814814814815\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["108 0.7339449541284404\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["109 0.7363636363636363\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["110 0.7387387387387387\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["111 0.7321428571428571\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["112 0.7345132743362832\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["113 0.7280701754385965\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["114 0.7304347826086957\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["115 0.7241379310344828\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["116 0.7264957264957265\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["117 0.7203389830508474\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["118 0.7226890756302521\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["119 0.7166666666666667\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["120 0.71900826446281\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["121 0.7213114754098361\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["122 0.7235772357723578\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["123 0.7258064516129032\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["124 0.72\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["125 0.7142857142857143\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["126 0.7086614173228346\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["127 0.7109375\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["128 0.7131782945736435\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["129 0.7153846153846154\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["130 0.7175572519083969\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["131 0.7121212121212122\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["132 0.7142857142857143\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["133 0.7164179104477612\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["134 0.7185185185185186\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["135 0.7205882352941176\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["136 0.7226277372262774\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["137 0.717391304347826\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["138 0.7194244604316546\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["139 0.7214285714285714\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["140 0.723404255319149\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["141 0.7253521126760564\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["142 0.7272727272727273\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["143 0.7291666666666666\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["144 0.7310344827586207\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["145 0.7328767123287672\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["146 0.7346938775510204\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["147 0.7364864864864865\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["148 0.7315436241610739\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["149 0.7333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["150 0.7284768211920529\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["151 0.7236842105263158\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["152 0.7254901960784313\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["153 0.7272727272727273\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["154 0.7290322580645161\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["155 0.7307692307692307\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["156 0.732484076433121\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["157 0.7341772151898734\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["158 0.7295597484276729\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["159 0.73125\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["160 0.7329192546583851\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["161 0.7283950617283951\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["162 0.7239263803680982\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["163 0.725609756097561\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["164 0.7212121212121212\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["165 0.7228915662650602\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["166 0.7245508982035929\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["167 0.7261904761904762\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["168 0.727810650887574\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["169 0.7294117647058823\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["170 0.7309941520467836\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["171 0.7325581395348837\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["172 0.7283236994219653\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["173 0.7298850574712644\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["174 0.7314285714285714\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["175 0.7329545454545454\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["176 0.7288135593220338\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["177 0.7247191011235955\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["178 0.7262569832402235\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["179 0.7277777777777777\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["180 0.7292817679558011\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["181 0.7252747252747253\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["182 0.726775956284153\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["183 0.7282608695652174\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["184 0.7297297297297297\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["185 0.7258064516129032\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["186 0.7219251336898396\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["187 0.7180851063829787\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["188 0.7142857142857143\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["189 0.7157894736842105\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["190 0.7172774869109948\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["191 0.71875\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["192 0.7150259067357513\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["193 0.7164948453608248\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["194 0.7128205128205128\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["195 0.7142857142857143\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["196 0.7157360406091371\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["197 0.7171717171717171\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["198 0.7135678391959799\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["199 0.715\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["200 0.7164179104477612\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["201 0.7178217821782178\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["202 0.7192118226600985\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["203 0.7205882352941176\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["204 0.7219512195121951\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["205 0.7233009708737864\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["206 0.7246376811594203\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["207 0.7259615384615384\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["208 0.7272727272727273\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["209 0.7285714285714285\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["210 0.7298578199052133\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["211 0.7311320754716981\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["212 0.7323943661971831\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["213 0.7336448598130841\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["214 0.7348837209302326\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["215 0.7361111111111112\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["216 0.7373271889400922\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["217 0.7385321100917431\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["218 0.7397260273972602\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["219 0.740909090909091\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["220 0.7420814479638009\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["221 0.7432432432432432\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["222 0.7443946188340808\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["223 0.7455357142857143\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["224 0.7466666666666667\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["225 0.7477876106194691\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["226 0.748898678414097\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["227 0.75\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["228 0.7510917030567685\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["229 0.7521739130434782\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["230 0.7532467532467533\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["231 0.7543103448275862\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["232 0.7553648068669528\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["233 0.7564102564102564\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["234 0.7574468085106383\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["235 0.7584745762711864\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["236 0.759493670886076\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["237 0.7605042016806722\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["238 0.7615062761506276\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["239 0.7625\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["240 0.7634854771784232\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["241 0.7644628099173554\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["242 0.7654320987654321\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["243 0.7663934426229508\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["244 0.7673469387755102\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["245 0.7682926829268293\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["246 0.7692307692307693\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["247 0.7701612903225806\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["248 0.7710843373493976\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["249 0.772\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["250 0.7729083665338645\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["251 0.7738095238095238\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["252 0.7747035573122529\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["253 0.7755905511811023\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["254 0.7764705882352941\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["255 0.77734375\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["256 0.7782101167315175\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["257 0.7790697674418605\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["258 0.7799227799227799\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["259 0.7807692307692308\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["260 0.7816091954022989\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["261 0.7824427480916031\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["262 0.7832699619771863\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["263 0.7840909090909091\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["264 0.7849056603773585\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["265 0.7857142857142857\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["266 0.7865168539325843\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["267 0.7873134328358209\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["268 0.7881040892193308\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["269 0.7888888888888889\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["270 0.7896678966789668\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["271 0.7904411764705882\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["272 0.7912087912087912\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["273 0.791970802919708\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["274 0.7927272727272727\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["275 0.7934782608695652\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["276 0.7942238267148014\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["277 0.7949640287769785\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["278 0.7956989247311828\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["279 0.7928571428571428\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["280 0.7935943060498221\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["281 0.7907801418439716\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["282 0.7915194346289752\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["283 0.7922535211267606\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["284 0.7929824561403509\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["285 0.7937062937062938\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["286 0.794425087108014\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["287 0.7951388888888888\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["288 0.7958477508650519\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["289 0.7965517241379311\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["290 0.7972508591065293\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["291 0.797945205479452\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["292 0.7986348122866894\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["293 0.7993197278911565\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["294 0.8\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["295 0.8006756756756757\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["296 0.797979797979798\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["297 0.7986577181208053\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["298 0.7993311036789298\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["299 0.8\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["300 0.8006644518272426\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["301 0.8013245033112583\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["302 0.801980198019802\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["303 0.8026315789473685\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["304 0.8032786885245902\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["305 0.803921568627451\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["306 0.8045602605863192\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["307 0.8051948051948052\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["308 0.8058252427184466\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["309 0.8064516129032258\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["310 0.8070739549839229\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["311 0.8076923076923077\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["312 0.8083067092651757\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["313 0.8089171974522293\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["314 0.8095238095238095\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["315 0.810126582278481\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["316 0.8107255520504731\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["317 0.8113207547169812\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["319 0.8119122257053292\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["320 0.8125\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["321 0.8130841121495327\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["322 0.8136645962732919\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["323 0.8111455108359134\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["324 0.8117283950617284\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["325 0.8123076923076923\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["326 0.8128834355828221\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["327 0.8134556574923547\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["328 0.8140243902439024\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["329 0.8145896656534954\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["330 0.8151515151515152\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["331 0.8157099697885196\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["332 0.8162650602409639\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["333 0.8168168168168168\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["334 0.8173652694610778\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["335 0.817910447761194\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["336 0.8184523809523809\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["337 0.8160237388724035\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["338 0.8136094674556213\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["339 0.8141592920353983\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["340 0.8147058823529412\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["341 0.8152492668621701\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["342 0.8157894736842105\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["343 0.8163265306122449\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["344 0.8168604651162791\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["345 0.8173913043478261\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["346 0.815028901734104\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["347 0.8155619596541787\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["348 0.8160919540229885\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["349 0.8166189111747851\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["350 0.8171428571428572\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["351 0.8176638176638177\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["352 0.8181818181818182\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["353 0.8186968838526912\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["354 0.8192090395480226\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["355 0.819718309859155\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["356 0.8202247191011236\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["357 0.8207282913165266\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["358 0.8212290502793296\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["359 0.8217270194986073\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["360 0.8222222222222222\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["361 0.8227146814404432\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["362 0.8232044198895028\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["363 0.8209366391184573\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["364 0.8214285714285714\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["365 0.821917808219178\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["366 0.8224043715846995\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["367 0.8201634877384196\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["368 0.8206521739130435\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["369 0.8184281842818428\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["370 0.8189189189189189\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["371 0.8194070080862533\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["372 0.8198924731182796\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["373 0.8203753351206434\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["374 0.820855614973262\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["375 0.8213333333333334\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["376 0.8218085106382979\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["377 0.8222811671087533\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["378 0.8227513227513228\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["379 0.8232189973614775\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["380 0.8236842105263158\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["381 0.8241469816272966\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["382 0.824607329842932\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["383 0.825065274151436\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["384 0.8255208333333334\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["385 0.825974025974026\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["386 0.8238341968911918\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["387 0.8242894056847545\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["388 0.8247422680412371\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["389 0.8251928020565553\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["390 0.8256410256410256\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["391 0.8260869565217391\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["392 0.826530612244898\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["393 0.8244274809160306\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["394 0.8248730964467005\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["395 0.8253164556962025\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["396 0.8257575757575758\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["397 0.8261964735516373\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["398 0.8266331658291457\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["399 0.8270676691729323\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["400 0.8275\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["401 0.827930174563591\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["402 0.8283582089552238\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["403 0.8287841191066998\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["404 0.8292079207920792\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["405 0.8296296296296296\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["406 0.8300492610837439\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["407 0.8304668304668305\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-956975a9b3eb>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_output = F.softmax(output)\n"]},{"output_type":"stream","name":"stdout","text":["408 0.8308823529411765\n"]}],"source":["\n","    from sklearn.metrics import roc_auc_score, accuracy_score\n","\n","    multimodal_model.eval()  # Set the multimodal_model to evaluation mode\n","    all_labels = []\n","    all_preds = []\n","\n","    with torch.no_grad():\n","        for bth_idx in range(0,len(test_data)):\n","            frames,mel,labels = test_dataset.__getitem__(bth_idx)\n","            if len(frames) != 0 :\n","              outputs = multimodal_model(frames,mel)\n","              labels = torch.unsqueeze(labels, dim=0)\n","              _, preds1 = torch.max(outputs, 1)\n","              _, preds2 = torch.max(labels, 1)\n","              all_labels.extend(preds2.cpu().numpy())\n","              all_preds.extend(preds1.cpu().numpy())\n","              accuracy = accuracy_score(all_labels, all_preds)\n","              print(bth_idx, accuracy)\n","    accuracy = accuracy_score(all_labels, all_preds)\n","\n","    print(f'Epoch {epoch + 1}/{num_epochs}, Accuracy: {accuracy}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTvVV4cpLpjQ"},"outputs":[],"source":["del checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAGUgDMcOPJr"},"outputs":[],"source":["torch.save(multimodal_model.state_dict(),'multi_modal0.pth')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YCLZitrn6vda"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3f0988bb144d402c9a8d61dd001b7b35":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a1d7b3de1dc4686b4b6045a1c2a2487","IPY_MODEL_c835c837b6c748f8bdf8c6f343749d5d","IPY_MODEL_9e5cf2c8791e4fabaee5a268d02f5d0b"],"layout":"IPY_MODEL_c6cdea92c21f4d228f5300ff17e45692"}},"9a1d7b3de1dc4686b4b6045a1c2a2487":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84adb3440c044db0977a0f6c6e1ca58e","placeholder":"​","style":"IPY_MODEL_a8499717904f4a78811b28d5a7cc21f7","value":"Downloading (…)rocessor_config.json: 100%"}},"c835c837b6c748f8bdf8c6f343749d5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad548e9bfe4c4666a0f4017a2709a0d6","max":255,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3fd2a35c54d24afcaa773ac39db0933e","value":255}},"9e5cf2c8791e4fabaee5a268d02f5d0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05f43b3b6d7b47a7b2eece922a3a28be","placeholder":"​","style":"IPY_MODEL_8cd202cc36ea47e4971b52915a63765c","value":" 255/255 [00:00&lt;00:00, 8.19kB/s]"}},"c6cdea92c21f4d228f5300ff17e45692":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84adb3440c044db0977a0f6c6e1ca58e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8499717904f4a78811b28d5a7cc21f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad548e9bfe4c4666a0f4017a2709a0d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fd2a35c54d24afcaa773ac39db0933e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05f43b3b6d7b47a7b2eece922a3a28be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cd202cc36ea47e4971b52915a63765c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"332168099f6c413095e2bb0f2377ec1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b1db89d43d74dd4960a307b58e9f71c","IPY_MODEL_1aad9672b8b944fd835cf1500072c4a1","IPY_MODEL_53a3345c21f74caabf22fa26b099dc99"],"layout":"IPY_MODEL_90a8b4ce0ed742eb9af562dc02f8c90e"}},"8b1db89d43d74dd4960a307b58e9f71c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_914b77d808594894ba871a59ffc7c02b","placeholder":"​","style":"IPY_MODEL_db9ba6357f1646f0b80c861c1328ec7f","value":"Downloading (…)lve/main/config.json: 100%"}},"1aad9672b8b944fd835cf1500072c4a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f921194c14e4d71b487f047a14a67a8","max":71813,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ec00445225243edb2026c6dad961fe1","value":71813}},"53a3345c21f74caabf22fa26b099dc99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a1ac803ef0a4210a04d8f18c8e62ff3","placeholder":"​","style":"IPY_MODEL_a9a0d58c0134430fbceea4e2a7aeefe6","value":" 71.8k/71.8k [00:00&lt;00:00, 1.94MB/s]"}},"90a8b4ce0ed742eb9af562dc02f8c90e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"914b77d808594894ba871a59ffc7c02b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db9ba6357f1646f0b80c861c1328ec7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f921194c14e4d71b487f047a14a67a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ec00445225243edb2026c6dad961fe1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a1ac803ef0a4210a04d8f18c8e62ff3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9a0d58c0134430fbceea4e2a7aeefe6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24dc9cd45d5644a09c02a8fd4eae36f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ed6ab70687e470798206c1ac7daafc1","IPY_MODEL_68eeff0e1a6a4ff7bf2f4bd98107a393","IPY_MODEL_4fc194aa3a074565b30c6de113b62d9a"],"layout":"IPY_MODEL_f9c7e24f0047449a9f8d25856058988f"}},"2ed6ab70687e470798206c1ac7daafc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5a28e8b0c874f0cb7741ae55fc2bc22","placeholder":"​","style":"IPY_MODEL_66e278b7e9c4412da2e7c7ffcf2c3b1e","value":"Downloading model.safetensors: 100%"}},"68eeff0e1a6a4ff7bf2f4bd98107a393":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27b9c2da62a24128bb8c0d008759f6f1","max":113412768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf0cbbd1a66d4d77b9f6e38a001b58cc","value":113412768}},"4fc194aa3a074565b30c6de113b62d9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a52234d35bf46c2a1d20aafd4d23fe3","placeholder":"​","style":"IPY_MODEL_517caecf9dd2476688a4629c81a14796","value":" 113M/113M [00:02&lt;00:00, 36.9MB/s]"}},"f9c7e24f0047449a9f8d25856058988f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5a28e8b0c874f0cb7741ae55fc2bc22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66e278b7e9c4412da2e7c7ffcf2c3b1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27b9c2da62a24128bb8c0d008759f6f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf0cbbd1a66d4d77b9f6e38a001b58cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a52234d35bf46c2a1d20aafd4d23fe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"517caecf9dd2476688a4629c81a14796":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}